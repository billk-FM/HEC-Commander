
Created with [Script Translator: Outline in Plain Language](https://github.com/billk-FM/HEC-Commander/blob/main/ChatGPT%20Examples/08_Script_Translator_-_Outline_in_Plain_Language.md)

For more detailed summaries of specific code cells or segments, use the GPT above (free version available) to re-summarize


## Summary of Code Cell 1: User Inputs and Configuration Parameters

This code cell is dedicated to defining various user inputs and configuration parameters for a data visualization script. It's designed to plot data from DSS (Data Storage System) files, commonly used in hydrology and water resources engineering. The main elements of this code cell include:

1. **DSS and Plotting Parameters**:
   - `DSS_Source_Path`: Specifies the file path where the DSS files are located.
   - `gauge_csv_file_name`: The name of the gauge data file in CSV format.
   - `river_stations`: A list of identifiers (like gauge station numbers) to filter the data.
   - `search_word`: A keyword to filter results from HMS (Hydrologic Modeling System) or RAS (River Analysis System) runs.
   - `plot_window_start`, `plot_window_end`: Define the time window for which data will be plotted.
   - `base_condition_dss`: A phrase to match time series, used to color code the plots.

2. **Time Series Type**:
   - `search_parameter1` and `search_parameter2`: Define the types of data to be searched in the DSS files, such as "STAGE" or "FLOW".

3. **Plot Customization**:
   - `bokeh_plot_width`, `bokeh_plot_height`: Dimensions for the Bokeh plot.
   - `bokeh_table_width`, `bokeh_table_height`: Dimensions for any associated Bokeh table.
   - `output_html_file_name`: The name of the output HTML file for the plot.
   - `bokeh_plot_title`: Title for the Bokeh plot.

4. **Additional Information**:
   - `chan_bottom_elevation_dict`: A dictionary mapping river station identifiers to their bottom elevation. This is used for depth calculations.

**Purpose and Usage**:
- The script appears to be set up for generating time series plots for hydrological data.
- Users need to input specific details like file paths, gauge station identifiers, and desired time windows.
- The plot dimensions and titles are customizable, suggesting an emphasis on user-friendly visualization.
- The script likely uses the Bokeh library for visualization, given the naming convention of the variables.

**Important Variables**:
- `DSS_Source_Path`, `gauge_csv_file_name`, `river_stations`, `search_word`, `plot_window_start`, `plot_window_end`, `base_condition_dss`
- `search_parameter1`, `search_parameter2`
- `bokeh_plot_width`, `bokeh_plot_height`, `bokeh_table_width`, `bokeh_table_height`, `output_html_file_name`, `bokeh_plot_title`
- `chan_bottom_elevation_dict`



## Summary of Code Cell 2: Example Gauge Data Format

This code cell provides an example of the expected format for the gauge data CSV file. It's a short cell that includes a commented-out multiline string, illustrating the structure of the CSV file used for plotting data. The key features of this format are:

1. **Headers**:
   - The first row lists "River Station" followed by identifiers for different stations.
   - The second row specifies whether the data for each station represents "STAGE" or "FLOW".
   - The third row starts with "Date" followed by unique identifiers for each gauge station (e.g., USGS station numbers).

2. **Data Entries**:
   - Subsequent rows represent time-stamped data entries.
   - The first column contains dates and times.
   - Following columns contain the data corresponding to each station and data type (stage or flow) specified in the headers.

**Purpose and Usage**:
- This format serves as a guideline for how the input CSV file should be structured.
- The script likely reads this file to extract hydrological data for visualization.
- Understanding this format is crucial for users who wish to input their data into the system.

**Important Points**:
- The cell is purely informational and does not execute any code.
- It's essential for users to format their data correctly to ensure the script functions as intended.



## Summary of Code Cell 3: Library Import and Installation Functions

This code cell is quite extensive and includes a series of functions and commands for importing and, if necessary, installing various Python libraries required for the script. The primary functionalities of this cell are:

1. **Library Installation Functions**:
   - `install_module(module_name)`: Checks if a module is installed, and if not, installs it using pip.
   - `python_version_check(version)`: Verifies if the current Python version matches the required version.
   - `download_and_install_wheel(wheel_url)`: Downloads and installs a Python wheel from a provided URL.
   - `install_osgeo_and_pydss()`: Attempts to import `osgeo`, and if unsuccessful, downloads and installs GDAL and PyDSS.

2. **Python Library Imports and Installation**:
   - A list named `modules` contains various libraries such as 'affine', 'rasterio', 'pandas', 'numpy', and 'bokeh'.
   - The script loops through this list, attempting to install each module using the `install_module` function.
   - After this, the script calls `install_osgeo_and_pydss` to ensure `osgeo` and `PyDSS` are available.
   - Then, it imports several libraries and functions, including `HecDss` from `pydsstools`, various functions from `datetime`, `matplotlib`, and `bokeh`.

3. **Bokeh Plot Configuration**:
   - The cell imports specific modules from Bokeh for data visualization, including tools for creating figures, handling data sources, and configuring hover tools.

4. **Data Processing Libraries**:
   - Libraries like `pandas`, `numpy`, and `matplotlib` are imported, indicating that the script involves data manipulation and visualization.
   - The script also includes machine learning related imports like `sklearn.metrics` for calculating mean squared error.

5. **Excel File Handling**:
   - Imports from `openpyxl` suggest handling of Excel files, possibly for data input or output.

**Purpose and Usage**:
- This cell ensures all necessary Python libraries are available and installed for the script to function correctly.
- It sets up the environment for data processing, analysis, and visualization.
- The use of Bokeh and matplotlib indicates a focus on creating interactive and static plots, respectively.
- The presence of data processing and machine learning libraries implies that the script might perform complex data manipulations and computations.

**Important Variables**:
- `modules`: A list of required Python modules.

**Note**: This cell is essential for setting up the environment. It makes the script more robust and user-friendly by automating the installation of dependencies.


## Summary of Code Cell 4: Processing and Filtering Gauge Data

This cell focuses on handling and preparing gauge data for plotting. The process involves reading a CSV file, filtering the data based on a specified time window, and saving the filtered data for further use. Here's a breakdown of its functionalities:

1. **Defining Pathname Pattern and Date Range**:
   - `pathname_pattern`: A string representing a pattern for pathname, probably for DSS file paths.
   - `plot_start_date`, `plot_end_date`: Convert the user-defined plot window start and end times into pandas datetime objects.

2. **Reading and Processing the Gauge Data CSV File**:
   - The script reads the header of the gauge data file and adjusts any duplicate column names.
   - It reads the main data, renaming the first column to 'Date' and ensuring it is in datetime format.
   - Any rows with invalid or missing dates (`NaT`) are dropped.

3. **Filtering Data Based on Date Range**:
   - The DataFrame `df` is filtered to include only data within the defined plot window (`plot_start_date` to `plot_end_date`).

4. **Saving Filtered Data**:
   - The script writes the filtered data to a new CSV file (`00_Gauge_data_plot_window.csv`).
   - The filtered data file is then set as the new `gauge_csv_file_name`.

5. **Output Statement**:
   - Prints a message indicating the time range for which data will be plotted.

**Purpose and Usage**:
- This cell ensures that only relevant data within the specified time window is used for plotting.
- It handles potential issues with duplicate column names and missing date values in the data.

**Important Variables**:
- `pathname_pattern`, `plot_start_date`, `plot_end_date`
- `header_rows`, `df`: DataFrames for the header and main data of the gauge CSV file.
- `gauge_csv_file_name`: Updated to point to the newly created filtered data file.

**Note**: This cell is essential for data integrity, ensuring that the plots generated later in the script accurately represent the specified time period.

Overall, this cell demonstrates careful handling and preprocessing of data, a crucial step in any data analysis workflow.


## Summary of Code Cell 5: Defining HTML Templates for Visualization

This cell is focused on defining HTML templates for visualizing statistical metrics in a Bokeh plot. These templates are used to format the display of various metrics with conditional coloring based on their values. The templates defined are for RMSE (Root Mean Square Error), Pearson's R, PBIAS (Percent Bias), and NSE (Nash-Sutcliffe Efficiency). 

1. **HTML Templates for Statistical Metrics**:
   - `rmse_template`: Formats the display of RMSE values. Values between 0 and 15 are colored green, while values greater than 15 are colored red.
   - `r_template`: For Pearson's R coefficient. Values between 0.9 and 1 are green, and values less than 0.9 are red.
   - `PBIAS_template`: For PBIAS. Values between -10 and 10 are green, and values outside this range are red.
   - `NSE_template`: For NSE. Values between 0.6 and 1 are green, and values between 0 and 0.6 are red.

2. **Template Structure**:
   - Each template is a string of HTML code with embedded JavaScript for conditional formatting.
   - The JavaScript functions (`colorfromint`) determine the color based on the metric's value.
   - The metric value is formatted to two decimal places and displayed with bold font.

**Purpose and Usage**:
- These templates are likely used in conjunction with Bokeh's DataTable widget to display statistical metrics related to hydrological model performance.
- The conditional formatting provides a quick visual indication of the metric's acceptability or performance level.

**Note**: This cell does not execute any data processing or plotting but sets up the aesthetic and functional aspects of data presentation for later use in the script.

Overall, this cell illustrates an emphasis on effective data communication through visual cues in the script's output, enhancing the interpretability of complex statistical metrics.


## Summary of Code Cell 6: Data Processing and Visualization Functions

This large code cell defines several functions for data processing and visualization. Due to the extensive content, I'll summarize the key functionalities and purposes:

1. **Data Adjustment Function**:
   - `adjust_dataframe(df, river_station, parameter)`: Adjusts data in a DataFrame based on the river station and parameter. It accounts for channel bottom elevation if the parameter is 'STAGE'.

2. **Excel Writing Functions**:
   - `write_data_to_excel(grouped_data, folder_path, file_name, adjust=False)`: Writes grouped data to an Excel file. It allows for optional data adjustment before writing.
   - `save_plotted_data_to_excel(grouped_data, folder_path)`: Saves plotted data to an Excel file without adjustment.
   - `save_plotted_data_to_excel_depth(grouped_data, folder_path)`: Saves plotted data with depth adjustment to an Excel file.

3. **Bokeh Plot Creation**:
   - The code includes logic to create Bokeh plots using data from grouped data sources.
   - It handles plot aesthetics like width, height, axis types, and titles.
   - The script dynamically generates line properties and assigns colors based on certain conditions (e.g., if the data is from `Gauge_data.csv` or contains `base_condition_dss`).
   - There's functionality for creating legends and adding hover tools for interactive plots.

4. **Statistical Calculations and Table Creation**:
   - The cell includes logic to calculate statistical metrics (RMSE, Pearson's R, etc.) and create Bokeh tables to display these metrics.
   - The tables use the HTML templates defined earlier for conditional formatting.

5. **Overall Plot Assembly**:
   - There's a structure for combining individual plots and tables into a comprehensive layout.

**Purpose and Usage**:
- These functions collectively handle the core tasks of data processing, analysis, and visualization.
- The script seems tailored for hydrological data analysis, focusing on both the visual and statistical aspects.
- The use of Bokeh suggests an emphasis on creating interactive, web-based plots.

**Note**: Due to the complexity and length of this cell, it encompasses a wide range of functionalities, from data manipulation to visual output generation, making it a central part of the script's operation.

## Summary of Code Cell 7: Iterating Over DSS Files and Plot Generation

This final code cell in the notebook is relatively short and is responsible for iterating over the DSS files in the specified source directory and generating plots using the previously defined functions. Here's an overview of its functionality:

1. **Directory Traversal**:
   - The script uses `os.walk()` to iterate through directories and files in the `DSS_Source_Path`.

2. **Condition-Based Processing**:
   - It checks if the `gauge_csv_file_name` file is present in the current directory.
   - If the file is found, it calls the `process_folder(root)` function to process the data and generate plots for that folder.

**Purpose and Usage**:
- This cell is the execution point where the script scans through the provided directory, identifies relevant data files, and initiates the processing and plotting routines.
- It implies that the script is designed to handle multiple DSS files and gauge data combinations, likely processing each one independently.

**Note**: This cell brings together all the previous setups, functions, and configurations to apply them to actual data files, resulting in the generation of plots and analyses.

In summary, this cell is the operational core of the script, where the data processing and visualization functions are applied to the real data set.



























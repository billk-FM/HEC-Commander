{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atlas 14 ASC Grid Summary Data Analysis Script\n",
    "Script 3/3 for Atlas 14 Spatial Variance Analysis\n",
    "\n",
    "Author: William (Bill) Katzenmeyer, P.E., C.F.M. (C.H. Fenstermaker and Associates, LLC) \n",
    "\n",
    "Source: https://github.com/billk-FM/HEC-Commander-Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries \n",
    "# only pandas needs installation,and should have been installed in previous scripts\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide path to a CSV file from previous script, the script will iterate over all files in the folder\n",
    "\n",
    "# Load the data from the CSV file (use an example file for the example plot)\n",
    "file_path = r'output_csv_by_polygon\\West_Fork_2D.csv'\n",
    "csv_data = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "# output_folder is the folder containing file_path\n",
    "output_csv_by_polygon_folder = os.path.dirname(file_path)\n",
    "print(f\"output_csv_by_polygon_folder: {output_csv_by_polygon_folder}\")\n",
    "\n",
    "\n",
    "# Display the first few rows of the dataframe to understand its structure\n",
    "display(csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract metadata from file name - adapted from previous script to work on the csv dataframe, and extract the metadata into columns of the dataframe\n",
    "\n",
    "# Define the folder containing the CSV files\n",
    "output_csv_by_polygon_folder = os.path.dirname(file_path)\n",
    "print(f\"output_csv_by_polygon_folder: {output_csv_by_polygon_folder}\")\n",
    "\n",
    "def extract_metadata_from_dataframe(dataframe):\n",
    "    \"\"\"\n",
    "    Extracts metadata from the 'File Name' column of the given dataframe.\n",
    "    \n",
    "    This function processes each filename to extract the return interval, duration, \n",
    "    duration units, and duration in minutes. The extracted metadata is added as new \n",
    "    columns to the dataframe.\n",
    "    \n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): The dataframe containing a 'File Name' column.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: The updated dataframe with new metadata columns.\n",
    "    \"\"\"\n",
    "    print(\"\\n-----   Extracting Metadata   -----\")\n",
    "    \n",
    "    def extract_metadata(filename):\n",
    "        \"\"\"\n",
    "        Extracts metadata from a given filename.\n",
    "        \n",
    "        Parameters:\n",
    "        filename (str): The name of the file from which to extract metadata.\n",
    "        \n",
    "        Returns:\n",
    "        tuple: A tuple containing the return interval, duration, duration units, \n",
    "               and duration in minutes.\n",
    "        \"\"\"\n",
    "        base_filename = os.path.basename(filename)\n",
    "        \n",
    "        # Extract return interval (numbers before \"yr\")\n",
    "        return_interval_match = re.search(r'(\\d+)yr', base_filename)\n",
    "        if return_interval_match:\n",
    "            return_interval = int(return_interval_match.group(1))\n",
    "        else:\n",
    "            raise ValueError(f\"Unable to extract return interval from filename: {base_filename}\")\n",
    "        \n",
    "        # Extract duration (2 numbers before \"ha\", \"da\", or \"ma\", which denote Hours Days or Minutes)\n",
    "        duration_match = re.search(r'(\\d{2})(ha|da|ma)', base_filename)\n",
    "        if duration_match:\n",
    "            duration = int(duration_match.group(1))\n",
    "            duration_units = duration_match.group(2)\n",
    "            if duration_units == \"ha\":\n",
    "                duration_minutes = duration * 60\n",
    "            elif duration_units == \"da\":\n",
    "                duration_minutes = duration * 60 * 24\n",
    "            elif duration_units == \"ma\":\n",
    "                duration_minutes = duration   \n",
    "        else:\n",
    "            raise ValueError(f\"Unable to extract duration from filename: {base_filename}\")\n",
    "        \n",
    "        return return_interval, duration, duration_units, duration_minutes\n",
    "    \n",
    "    # Apply the extract_metadata function to each row in the dataframe\n",
    "    metadata = dataframe['File Name'].apply(extract_metadata)\n",
    "    dataframe[['Return Interval', 'Duration', 'Duration Units', 'Duration Hours']] = pd.DataFrame(metadata.tolist(), index=dataframe.index)\n",
    "    \n",
    "    return dataframe\n",
    "\n",
    "# Extract metadata and add it to the dataframe\n",
    "csv_data_with_metadata = extract_metadata_from_dataframe(csv_data)\n",
    "\n",
    "# Save the updated dataframe back to the CSV file\n",
    "csv_data_with_metadata.to_csv(file_path, index=False)\n",
    "\n",
    "# Display the updated dataframe\n",
    "print(\"csv_data_with_metadata\")\n",
    "display(csv_data_with_metadata)\n",
    "\n",
    "# now, repeat for all csv files in the output_csv_by_polygon folder\n",
    "\n",
    "# create a list of all csv (files ending in .csv) in the output_csv_by_polygon folder, then start a loop\n",
    "# create variable csv_from_folder with the path of the current file\n",
    "# populate csv_data with the data for the current file\n",
    "# then, call the extract_metadata_from_dataframe function for each file\n",
    "\n",
    "# Create a list of all CSV files in the output_csv_by_polygon folder\n",
    "csv_files = [os.path.join(output_csv_by_polygon_folder, f) for f in os.listdir(output_csv_by_polygon_folder) if f.endswith('.csv')]\n",
    "\n",
    "# Initialize an empty list to accumulate dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Loop through each CSV file\n",
    "for csv_file in csv_files:\n",
    "    # Read the CSV file into a dataframe\n",
    "    csv_data = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Print the dataframe name and display the dataframe\n",
    "    print(f\"csv_data from {csv_file}\")\n",
    "    #display(csv_data)\n",
    "    \n",
    "    # Extract metadata and add it to the dataframe\n",
    "    csv_data_with_metadata = extract_metadata_from_dataframe(csv_data)\n",
    "    \n",
    "    # Save the updated dataframe back to the CSV file\n",
    "    csv_data_with_metadata.to_csv(csv_file, index=False)\n",
    "    \n",
    "    # Print the updated dataframe name and display the updated dataframe\n",
    "    #print(f\"csv_data_with_metadata from {csv_file}\")\n",
    "    #display(csv_data_with_metadata)\n",
    "    \n",
    "    # Append the updated dataframe to the list\n",
    "    dataframes.append(csv_data_with_metadata)\n",
    "\n",
    "# Print completion message\n",
    "print(\"Metadata extraction complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create HUC-specific plots for each duration and return interval\n",
    "# For each Return Interval, create a bar chart showing the min, mean, and max for each duration\n",
    "def plot_min_mean_max_by_duration(dataframe, output_folder, file_name):\n",
    "    \"\"\"\n",
    "    Create bar charts showing the minimum, mean, and maximum values for each duration\n",
    "    within the specified return intervals.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): The input dataframe containing rainfall data.\n",
    "    output_folder (str): The folder where the plots will be saved.\n",
    "    file_name (str): The name of the file being processed, used for plot titles.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    unique_return_intervals = dataframe['Return Interval'].unique()\n",
    "    \n",
    "    for return_interval in unique_return_intervals:\n",
    "        # Filter the dataframe for the current return interval\n",
    "        subset = dataframe[dataframe['Return Interval'] == return_interval]\n",
    "        \n",
    "        # Sort the subset by Duration Hours\n",
    "        subset = subset.sort_values(by='Duration Hours')\n",
    "        \n",
    "        plt.figure(figsize=(16, 9))  # Set the figure size for the plot\n",
    "        bar_width = 0.25  # Define the width of the bars\n",
    "        index = range(len(subset))  # Create an index for the x-axis\n",
    "        \n",
    "        # Create bar plots for Min, Mean, and Max values\n",
    "        plt.bar(index, subset['Min (inches)'], bar_width, label='Min (inches)')\n",
    "        plt.bar([i + bar_width for i in index], subset['Mean (inches)'], bar_width, label='Mean (inches)')\n",
    "        plt.bar([i + 2 * bar_width for i in index], subset['Max (inches)'], bar_width, label='Max (inches)')\n",
    "        \n",
    "        # Calculate and display percent variance\n",
    "        for i, (min_val, max_val) in enumerate(zip(subset['Min (inches)'], subset['Max (inches)'])):\n",
    "            percent_variance = ((max_val - min_val) / min_val) * 100\n",
    "            plt.text(i + bar_width, max_val, f'{percent_variance:.1f}%', \n",
    "                     ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        # Set the title and labels for the plot\n",
    "        title = f'Atlas 14 Variance within {os.path.splitext(os.path.basename(file_name))[0].replace(\"_\", \" \")} Watershed \\nfor Return Interval: {return_interval} years'\n",
    "        plt.title(title)\n",
    "        plt.xlabel('Duration (Minutes)')\n",
    "        plt.ylabel('Inches')\n",
    "        plt.xticks([i + bar_width for i in index], subset['Duration Hours'])\n",
    "        plt.legend(title='Legend', labels=['Min (inches)', 'Mean (inches)', 'Max (inches)', 'Percent variance from min to max'])\n",
    "        plt.grid(True)  # Add grid lines to the plot\n",
    "        \n",
    "        # Save the plot\n",
    "        plot_filename = f\"{os.path.splitext(os.path.basename(file_name))[0]}_{return_interval}yr.png\"\n",
    "        plt.savefig(os.path.join(output_folder, plot_filename))\n",
    "        plt.close()  # Close the plot to free memory\n",
    "        print(f\"Bar chart created for Return Interval: {return_interval} years\")\n",
    "\n",
    "# Create a list of all CSV files in the output_csv_by_polygon folder\n",
    "csv_files = [os.path.join(output_csv_by_polygon_folder, f) for f in os.listdir(output_csv_by_polygon_folder) if f.endswith('.csv')]\n",
    "\n",
    "# Loop through each CSV file\n",
    "for csv_file in csv_files:\n",
    "    # Read the CSV file into a dataframe\n",
    "    csv_data = pd.read_csv(csv_file)\n",
    "    \n",
    "    print(f\"Processing csv_data from {csv_file}\")\n",
    "    \n",
    "    # Extract metadata and add it to the dataframe\n",
    "    csv_data_with_metadata = extract_metadata_from_dataframe(csv_data)\n",
    "    \n",
    "    # Create output folder for plots\n",
    "    output_folder = os.path.join(os.path.dirname(csv_file), os.path.splitext(os.path.basename(csv_file))[0])\n",
    "    os.makedirs(output_folder, exist_ok=True)  # Create the output folder if it doesn't exist\n",
    "    \n",
    "    # Call the function to create bar charts\n",
    "    plot_min_mean_max_by_duration(csv_data_with_metadata, output_folder, csv_file)\n",
    "    \n",
    "    print(f\"Plots created for {csv_file}\")\n",
    "\n",
    "print(\"Processing complete for all CSV files\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mean/max by polygon\n",
    "\n",
    "def plot_min_mean_max_by_polygon(dataframes, output_folder, duration, return_interval):\n",
    "    \"\"\"\n",
    "    Creates a bar plot showing the minimum, mean, and maximum rainfall (in inches) \n",
    "    across different watersheds for a specified duration and return interval.\n",
    "\n",
    "    Parameters:\n",
    "    dataframes (list): A list of pandas DataFrames containing rainfall data.\n",
    "    output_folder (str): The folder where the plot will be saved.\n",
    "    duration (int): The duration in hours for which the plot is created.\n",
    "    return_interval (int): The return interval in years for which the plot is created.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, 6))  # Set the figure size for the plot\n",
    "    bar_width = 0.25  # Set the width of the bars in the bar chart\n",
    "    index = range(len(dataframes))  # Create an index for the x-axis based on the number of dataframes\n",
    "    \n",
    "    # Extract minimum, mean, and maximum values for the specified duration and return interval\n",
    "    min_values = [df[(df['Duration Hours'] == duration) & (df['Return Interval'] == return_interval)]['Min (inches)'].values[0] for df in dataframes]\n",
    "    mean_values = [df[(df['Duration Hours'] == duration) & (df['Return Interval'] == return_interval)]['Mean (inches)'].values[0] for df in dataframes]\n",
    "    max_values = [df[(df['Duration Hours'] == duration) & (df['Return Interval'] == return_interval)]['Max (inches)'].values[0] for df in dataframes]\n",
    "    \n",
    "    # Create bar plots for minimum, mean, and maximum values\n",
    "    plt.bar(index, min_values, bar_width, label='Min (inches)')\n",
    "    plt.bar([i + bar_width for i in index], mean_values, bar_width, label='Mean (inches)')\n",
    "    plt.bar([i + 2 * bar_width for i in index], max_values, bar_width, label='Max (inches)')\n",
    "    \n",
    "    # Display actual values above each bar\n",
    "    for i, (min_val, mean_val, max_val) in enumerate(zip(min_values, mean_values, max_values)):\n",
    "        plt.text(i, min_val, f'{min_val:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "        plt.text(i + bar_width, mean_val, f'{mean_val:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "        plt.text(i + 2 * bar_width, max_val, f'{max_val:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    # Set the title and labels for the plot\n",
    "    title = f'Atlas 14 Variance Across Watersheds\\nfor Duration: {duration} hours, Return Interval: {return_interval} years'\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Watersheds')\n",
    "    plt.ylabel('Inches')\n",
    "    plt.xticks([i + bar_width for i in index], [os.path.splitext(os.path.basename(df.name))[0].replace(\"_\", \" \") for df in dataframes], rotation=45, ha='right')\n",
    "    plt.legend(title='Legend', labels=['Min (inches)', 'Mean (inches)', 'Max (inches)'])\n",
    "    plt.grid(True)  # Add grid lines to the plot\n",
    "    plt.tight_layout()  # Adjust layout to prevent clipping of tick-labels\n",
    "    \n",
    "    # Save the plot\n",
    "    plot_filename = f\"Regional_Plot_{duration}hr_{return_interval}yr.png\"\n",
    "    plt.savefig(os.path.join(output_folder, plot_filename))  # Save the figure to the specified output folder\n",
    "    print(f\"output folder {output_folder}/{plot_filename} written\")\n",
    "    plt.close()  # Close the plot to free memory\n",
    "    print(f\"Regional bar chart created for Duration: {duration} hours, Return Interval: {return_interval} years\")\n",
    "\n",
    "# Define the folder containing the CSV files\n",
    "output_csv_by_polygon_folder = r'h:\\2202134.00C_LWI_Region4\\Technical\\Regional Design Storm Models\\Atlas 14 Assistant\\output_csv_by_polygon'\n",
    "\n",
    "# Create a list of all CSV files in the output_csv_by_polygon folder\n",
    "csv_files = [os.path.join(output_csv_by_polygon_folder, f) for f in os.listdir(output_csv_by_polygon_folder) if f.endswith('.csv')]\n",
    "\n",
    "# Create a list to store all dataframes\n",
    "all_dataframes = []\n",
    "\n",
    "# Loop through each CSV file\n",
    "for csv_file in csv_files:\n",
    "    # Read the CSV file into a dataframe\n",
    "    csv_data = pd.read_csv(csv_file)\n",
    "    \n",
    "    print(f\"Processing csv_data from {csv_file}\")  # Inform the user about the current file being processed\n",
    "    \n",
    "    # Extract metadata and add it to the dataframe\n",
    "    csv_data_with_metadata = extract_metadata_from_dataframe(csv_data)\n",
    "    \n",
    "    # Add the file name as an attribute to the dataframe\n",
    "    csv_data_with_metadata.name = csv_file\n",
    "    \n",
    "    # Append the dataframe to the list\n",
    "    all_dataframes.append(csv_data_with_metadata)\n",
    "\n",
    "# Create output folder for regional plots\n",
    "regional_output_folder = os.path.join(output_csv_by_polygon_folder, \"Regional Plots\")\n",
    "os.makedirs(regional_output_folder, exist_ok=True)  # Create the output folder if it doesn't exist\n",
    "print(regional_output_folder)\n",
    "\n",
    "# Get unique durations and return intervals\n",
    "unique_durations = all_dataframes[0]['Duration Hours'].unique()  # Extract unique durations from the first dataframe\n",
    "unique_return_intervals = all_dataframes[0]['Return Interval'].unique()  # Extract unique return intervals from the first dataframe\n",
    "\n",
    "# Create regional plots for each combination of duration and return interval\n",
    "for duration in unique_durations:\n",
    "    for return_interval in unique_return_intervals:\n",
    "        plot_min_mean_max_by_polygon(all_dataframes, regional_output_folder, duration, return_interval)  # Call the plotting function for each combination\n",
    "\n",
    "print(\"Processing complete for all CSV files\")  # Inform the user that processing is complete\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Atlas14_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

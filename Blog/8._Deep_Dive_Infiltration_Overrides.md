# Modification of HEC-RAS 2D Geometry Infiltration Base Overrides using H5py

## Introduction
HEC-RAS (Hydrologic Engineering Center's River Analysis System) is a widely used software for hydrological modeling and river analysis. One of the critical components in these models is the accurate representation of infiltration parameters. However, manually updating these parameters can be time-consuming and error-prone, especially when dealing with multiple scenarios or large datasets. This is where programmatic modification using Python and the H5py library comes into play, enabling efficient and automated updates to infiltration base overrides in HEC-RAS 2D geometries.

## Background
As of HEC-RAS version 6.0, HDF5 files (.hdf) are used to store and organize geometry, results, terrain, land cover and infiltration data layer information.  The geometry HDF files follow a specific structure are built dynamically from the ASCII geometry file each time the geometry is saved, creating a binary digital twin using the legacy plain text geometry file as input. 

To achieve programmatic modification of HDF files, we use the H5py library in Python which provides a convenient way to interact with and modify these HDF5 files. By leveraging the power of H5py and AI-assisted coding, we can automate the process of updating infiltration parameters to assist in HEC-RAS calibration and validation workflows.

## Why Modify the Geometry File instead of the Infiltration Layer
There are multiple way to achieve infiltration scaling using HEC-RAS and RASMapper.  The manual method involves simply editing the infiltration tables, and keeping notes within the geometry description to note which scale factors were utilized.  While this is feasible for a limited number of variations, the labor and potential for human error makes it less than optimal when performing large run sets.  The next logical step is to programmatically vary the infiltration layer HDF, where the infiltration value tables are stored.  However, this is not compatible with parallelization, as only one combination of infiltration parameters can be run at a time, or on-the-fly programmatic modifications would be needed that could introduce difficult-to-diagnose errors in the results.  

Ultimately, it determined that calibration regions defined within the geometry file itself was the most optimal method, as it provides a transparent and definitive listing of all parameters utilized in each set of results.  Modification of the geometry HDF file allow multiple variations to persist and be verifiable, as the full geometry including base overrides are copied into the results. This enables mass parallelization without the need for explicit recordkeeping within the geometry description or additional analysis needed to verify which infiltration values and scale factors were used.  The only required step is the addition of an infiltration calibration region within the geometry, which creates all of the necessary tables in the HDF file.  

When writing the infiltration values to the geometry HDF File, the base override values are modified, and not the calibration region itself.  This makes the actual calibration region irrelevant (one must be present, but its shape and position does not affect the script operation), and allows uniform scaling across the entire model domain without relying on the user to correctly draw or import a calibration region.  However, the function provided below could be easily repurposed to modify multiple calibration regions defined within a geometry for more demanding workflows.

One last thing!  You may have noticed that I mentioned that the geometry HDF is dynamically generated.  So doesn't that mean that any information that is written there, will be overwritten on the next save?  Well, infiltration layers are actually one of the only bits of data that *are not* stored anywhere in the ASCII geometry file.  Because the ASCII geometry file is a legacy file type that will eventually no longer be supported, new features are being incorporated in HDF format directly without backporting to the ASCII format.  Infiltration layers in RASMapper just so happen to be one of those features.  Go ahead, search the .gxx file for infiltration table values, you won't find them! Therefore the tables in the geometry HDF file are the primary storage location for that data, and it does not get dynamically overwritten when the geometry is subsequently saved. 

This might not seem like a big deal right now - it's only the infiltration parameters, right?  But HEC-RAS is moving towards HDF for all new features, and eventually will drop support for the ASCII geometry file.  I predict that this blog will only become more useful over time as more features and options become programmatically modifiable through HDF file manipulation.  

## Technical Deep Dive: Using H5py to Modify .gxx.hdf Files
Let's dive into the technical details of the H5py python function I used to modify the .gxx.hdf files in HEC-RAS. These files follow a specific structure, and understanding this structure is crucial for making accurate modifications. The key function that enables the programmatic update of infiltration base overrides is `scale_infiltration_data`. Here's a breakdown of how this function works:

'''
def scale_infiltration_data(hdf_file_path, infiltration_df, scale_md, scale_id, scale_pr):
    hdf_path_to_overwrite = '/Geometry/Infiltration/Base Overrides'
    
    with h5py.File(hdf_file_path, 'a') as hdf_file:
        if hdf_path_to_overwrite in hdf_file:
            del hdf_file[hdf_path_to_overwrite]

        dt = np.dtype([
            ('Land Cover Name', 'S7'),
            ('Maximum Deficit', 'f4'),
            ('Initial Deficit', 'f4'),
            ('Potential Percolation Rate', 'f4')
        ])

        structured_array = np.zeros(infiltration_df.shape[0], dtype=dt)
        structured_array['Land Cover Name'] = np.array(infiltration_df['Name'].astype(str).values.astype('|S7'))
        structured_array['Maximum Deficit'] = infiltration_df['Maximum Deficit'].values.astype(np.float32)
        structured_array['Initial Deficit'] = infiltration_df['Initial Deficit'].values.astype(np.float32)
        structured_array['Potential Percolation Rate'] = infiltration_df['Potential Percolation Rate'].values.astype(np.float32)

        hdf_file.create_dataset(
            hdf_path_to_overwrite,
            data=structured_array,  
            dtype=dt,
            compression='gzip',
            compression_opts=1,
            chunks=(100,),
            maxshape=(None,)
        )
        
    return infiltration_df
'''

The function takes the following arguments:
- `hdf_file_path`: The path to the .gxx.hdf file to be modified.
- `infiltration_df`: A pandas DataFrame containing the infiltration data to be scaled and written to the HDF5 file.
- `scale_md`, `scale_id`, `scale_pr`: Scale factors for Maximum Deficit, Initial Deficit, and Potential Percolation Rate, respectively.

The function performs the following steps:
- Opens the HDF5 file in append mode using `h5py.File()`.
- Checks if the dataset to be overwritten exists and deletes it if necessary.
- Defines a structured data type (dt) that matches the expected structure in the HDF5 file.
- Creates a structured array using the infiltration DataFrame and the defined data type.
- Writes the structured array to the HDF5 file using `create_dataset()`, specifying compression options and chunk size.
- Returns the scaled infiltration DataFrame for verification purposes.

It's important to note that the function uses specific data types and compression options that are compatible with HEC-RAS. Modifying these options may lead to issues with the HEC-RAS solver.

## Implementing the scale_infiltration_data Function in Your Workflow
To integrate the `scale_infiltration_data` function into your existing Python workflow, follow these steps:
- Ensure that you have the h5py and pandas libraries installed in your Python environment.
- Prepare your infiltration data as a pandas DataFrame with the required columns:
  - 'Name': Land cover names
  - 'Maximum Deficit'
  - 'Initial Deficit'
  - 'Potential Percolation Rate'

Here's an example of creating a sample DataFrame:
''' 
data = {
    'Name': ['Grass', 'Concrete', 'Soil'],
    'Maximum Deficit': [7, 1, 5],
    'Initial Deficit': [2, 0.1, 1.75],
    'Potential Percolation Rate': [1, 0.25, 0.8]
}
infiltration_df = pd.DataFrame(data)
'''

- Specify the path to your .gxx.hdf file and the desired scale factors:
''' 
hdf_file_path = 'path_to_your_hdf5_file.hdf5'
scale_md = 1.2
scale_id = 1.1
scale_pr = 0.9
'''

- Call the `scale_infiltration_data` function with the appropriate arguments:
''' 
scaled_df = scale_infiltration_data(hdf_file_path, infiltration_df, scale_md, scale_id, scale_pr)
'''

- Verify the changes by inspecting the scaled DataFrame returned by the function:
''' 
print("Scaled Infiltration Data:")
print(scaled_df)
'''

## Challenges and Solutions
When implementing the `scale_infiltration_data` function, you may encounter some challenges related to the specific HDF5 options required by the HEC-RAS unsteady solver. Here are a few common issues and their solutions:
- **Incorrect HDF5 Optionsin H5py**: The most common challenge when editing geometry files is using the correct HDF5 options in H5py that exactly match the existing geometry HDF file. The RAS unsteady solver requires strict adherence to the original structured array, chunking, shape, and compression options when making edits to the .gxx.hdf file. Failure to use the exact same options can result in solver errors.
  - **Solution**: Use HDFView, a visual tool for browsing and editing HDF5 files, to inspect the existing HDF5 file and ensure that the options used in the `scale_infiltration_data` function match precisely.  Use the "General Object Info" tab for a quick reference to all of the required info:

<p align="center">
  <img src="img/Infiltration_hdfview_ss.png" alt="Slide 2" style="border: 2px solid black; width: 75%;"/>
</p> 
 
  - **HDFView Download**: [https://www.hdfgroup.org/downloads/hdfview/](https://www.hdfgroup.org/downloads/hdfview/)  Navigating to the table of interest and going to the "General Object Info" tab will expose all of the HD options needed to succesfully recreate the dataset with H5py.
- **Complex HDF5 Options**: Setting the correct HDF5 options programmatically can be challenging, especially when dealing with structured arrays, compression, and chunking.
  - **Solution**: Leverage AI-assisted coding techniques, such as using the h5py documentation and examples, to set the parameters correctly.  Vision models can be used to ingest screenshots of HDFView directly.
  - **H5py Documentation - Datasets**: [https://docs.h5py.org/en/stable/high/dataset.html](https://docs.h5py.org/en/stable/high/dataset.html)
- **Lack of Examples**: Finding specific examples of editing HEC-RAS geometry files using Python is difficult, as the infiltration layers are currently the only major option stored in the geometry HDF that isn't dynamically overwritten from the ASCII geometry.  Combined with the need for an exact, in-kind replacement of the entire data structure each time a value is updated, there were simply are no examples available online for editing the HEC-RAS geometry HDF (which this blog seeks to ameliorate). 
  - **Solution**: Refer to the RAS-Commander Notebook, specifically Code Cell #9, which demonstrates how to update geometry HDF files with new infiltration grid base overrides. This code cell provides a practical example of using the `scale_infiltration_data` function and can serve as a starting point for your own implementation.
  - **RAS-Commander Notebook - Code Cell #9**: [https://github.com/billk-FM/HEC-Commander/blob/main/RAS-Commander/RAS-Commander%20_1.0.ipynb](https://github.com/billk-FM/HEC-Commander/blob/main/RAS-Commander/RAS-Commander%20_1.0.ipynb)

## Conclusion
Programmatic modification of HEC-RAS 2D geometries using H5py provides a powerful and efficient way to update infiltration base overrides. By automating the process, you can save time, reduce errors, and easily handle multiple scenarios. The `scale_infiltration_data` function demonstrated in this blog post serves as a foundation for integrating this functionality into your hydrological modeling workflows.  This functionality is already integrated into RAS-Commander, however I felt it was worth a deep dive to explore the specific options and data structures needed, as well as explain the logic behind the approach and the potential usefulness of this example as HEC-RAS versions advance and more features are implemented only in the geometry HDF files.  

The ability to programmatically modify infiltration base overrides opens up new possibilities for automated sensitivity analysis, calibration, and scenario testing in HEC-RAS 2D models. By leveraging the power of functions provided above, you can integrate this functionality into your own python automation workflows.  

Also, this should serve as yet another example of the power of AI-assisted coding for water resources engineers!  To adapt this code for your own use, just drop this entire .md file (copy/paste or drag and drop) into your favorite LLM provider (ChatGPT, Claude, Gemini or Llama3) and ask for a variation that suits your needs!  Happy coding and happy modeling!

## References and Further Reading

- **HDFView Download**: [https://www.hdfgroup.org/downloads/hdfview/](https://www.hdfgroup.org/downloads/hdfview/)
- **H5py Documentation - Datasets**: [https://docs.h5py.org/en/stable/high/dataset.html](https://docs.h5py.org/en/stable/high/dataset.html)
- **RAS-Commander Notebook - Code Cell #9**: [https://github.com/billk-FM/HEC-Commander/blob/main/RAS-Commander/RAS-Commander%20_1.0.ipynb](https://github.com/billk-FM/HEC-Commander/blob/main/RAS-Commander/RAS-Commander%20_1.0.ipynb)
- **HEC-RAS Documentation**: [https://www.hec.usace.army.mil/software/hec-ras/documentation.aspx](https://www.hec.usace.army.mil/software/hec-ras/documentation.aspx)
- **RAS Commander Blog**: [https://rascommander.com/blog/](https://rascommander.com/blog/)

For more detailed information and additional examples, refer to the RAS Commander blog and the HEC-RAS documentation.

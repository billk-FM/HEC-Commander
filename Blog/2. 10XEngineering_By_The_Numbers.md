# From 10x to 0.25x Engineering: By The Numbers

10x Engineering with AI: By the Numbers
Introduction
This is a follow-up to my previous post about 10x engineering and water resources. The shrewd reader who looked at the numbers should have come away asking, “You only use 10 machines. How did you get a greater than 10x speed improvement?” It's a valid question that highlights the core of 10x engineering - not just scaling up resources, but also optimizing them with a data-driven approach.  The foundation of this approach was benchmarking large 2D HEC-RAS models to understand how they scale

Fenstermaker's local compute cluster was utilized as a baseline, and runtimes for the benchmark model were converted to unit runtimes.  This allows a direct comparison across platforms with greater unit runtimes denoting slower overall model performance, and lower unit runtimes indicating faster overall model performance.  These findings are summarized on the slide below:


<p align="center">
  <img src="img/Slide2.PNG" alt="Slide 2" style="border: 2px solid black;"/>
</p>

<br/><br/>
# Efficiency Optimization: The Power of Benchmarking
When we look at the figures from our case study, it's evident that our approach leveraged efficiency, not just raw performance. I did mention that running with "All Cores" (8) resulted in a 70% performance increase over a 2-core setting.  A quick back of the napkin scribble reveals that a 400% increase in compute effort (8 cores) only managed to generate a 70% decrease in runtime?  How am I able to make this statement so definitively.  Well, by benchmarking of course!  



<br/><br/>

<p align="center">
  <img src="img/Slide6.PNG" alt="Slide 6" style="border: 2px solid black;"/>
</p>

<br/><br/>


The Non-Linear Efficiency Curve
Referencing the graphs in the PowerPoint, the 'Unit Runtime vs Cores' and 'CPU Efficiency vs Cores' slides highlight a fundamental principle in computational optimization: efficiency does not scale linearly with resources. As we increased core usage, the runtime improved dramatically up to a point, but then gains tapered off. This diminishing return on investment illustrates the critical balance between resource input and output efficiency—a balance we meticulously maintained throughout the West Fork project.
Implications and Practical Applications

The implications of our findings are profound. We've demonstrated that in the ecosystem of computational work, efficiency is not a straight path but a complex curve that requires understanding and respect. The key is not just to add more cores or computing power but to tailor the usage to the task at hand.


<br/><br/>

<p align="center">
  <img src="img/CloudProblems.jpg" alt="CloudProblems.jpg" style="border: 2px solid black;"/>
</p>

<br/><br/>

# Local Compute vs Cloud Costs

## 1. Introduction to Benchmarking and Data Driven Analysis

## 2. The Latency Impact of Cloud Systems on GIS Operations

A critical aspect contributing to this downturn is the inherent latency issues in cloud systems, which significantly impede GIS operations. For water resource engineers, tools like RASMAPPER are essential. However, benchmarking reveals that operations within RASMAPPER – including opening, closing, saving, and editing terrains – are 20-80% slower on cloud systems, averaging around a 60% reduction in performance. This slowdown isn't just a minor inconvenience; it's a substantial barrier that extends model development timelines far beyond their intended schedules.

This 60% reduction in performance, compounded by user interface delays, creates a ripple effect. Tasks that were once quick and efficient become drawn-out ordeals, significantly impacting project timelines and productivity on even the fastest available cloud storage systems. The impact is not just felt in the time taken to complete these tasks but also in the quality of work. Engineers, bogged down by sluggish systems, are unable to perform at their best, leading to a cascading effect on overall project outcomes.



## 3. Local vs. Cloud Infrastructure for HEC-RAS

When it comes to HEC-RAS modeling, a cornerstone in water resources engineering, the choice between local and cloud infrastructure becomes critical. Local setups, even those as simple as a workstation with a USB-C hard drive, generally outperform their cloud counterparts for these specific tasks. This superiority is not just about raw computing power; it's about the suitability of the infrastructure for the specific demands of GIS operations and HEC-RAS modeling.

Public cloud infrastructures, despite their massive scale and resources, consistently fall short in meeting the unique demands of water resource engineering applications. The scale efficiencies of cloud systems, often touted as their biggest advantage, come with hidden performance costs. These costs are not equally distributed across all applications and users. For tasks like RASMAPPER operations and HEC-RAS modeling, which involve frequent, small-scale data read/write operations, these performance costs can be particularly burdensome, leading to significant inefficiencies.

<br/><br/>

<p align="center">
  <br/>Slide:<br/>
  <img src="img/Slide3.PNG" alt="Slide 3" style="border: 2px solid black;"/>
</p>

<br/><br/>

## 4. Specific Challenges for GIS Workflows in the Cloud

The inefficiencies of cloud infrastructure become even more pronounced when examining the workflows common in GIS operations. These workflows often involve numerous small, frequent data transactions – a type of operation that cloud systems are not optimized for. HEC-RAS modeling, which lacks GPU acceleration and is heavily reliant on sequential data access, is notably ill-suited for the cloud environment.

This mismatch leads to a marked decrease in efficiency. What might be a routine operation on a local setup becomes a sluggish and frustrating process on the cloud. This not only slows down the overall workflow but also impacts the quality of the modeling work. The lag in processing and data handling can lead to delays in decision-making and, in some cases, compromise the accuracy of the models due to truncated or rushed analysis.

The implications of these challenges are profound. They not only affect the day-to-day work of engineers but also have broader implications for project timelines, costs, and ultimately the effectiveness of water resource management strategies.

## 5. Industry Trends vs. Practical Insights

Despite the growing trend towards cloud adoption in various sectors, including water resources engineering, practical experiences paint a different picture. Specifically, for HEC-RAS modeling, the movement towards cloud infrastructure appears to be more of a step backward than forward. This viewpoint is not just based on theoretical assumptions but is rooted in real-world experiences and extensive benchmarking.

As someone deeply embedded in the industry, I offer these insights not just as observations but as a caution to my fellow professionals and LinkedIn followers. The allure of cloud computing, with its promise of scalability and ease of access, can be tempting. However, it's crucial to assess the suitability of these systems for specific applications like HEC-RAS modeling. Blind adoption of cloud solutions, without considering their impact on productivity and project outcomes, can lead to significant setbacks.

## 6. Deep Dive into Performance and Benchmarking

The performance issues with cloud systems are not mere speculation; they are confirmed by thorough benchmarking. Various models, especially large 2D models in HEC-RAS, consistently demonstrate performance issues when operated on cloud platforms. The primary culprit is large matrix operations, which are integral to these models but are handled inefficiently by cloud servers.

These benchmarking exercises reveal a consistent pattern: cloud systems, regardless of their configurations or the scale of resources thrown at them, struggle with the computational demands of large-scale water resource models. The performance hit is not marginal but substantial, leading to significantly extended project timelines and increased costs.

In future discussions, I plan to delve deeper into the specifics of these benchmarking efforts. We'll explore the nuances of scaling, efficiency, and performance in both cloud and local server environments. This will provide a more detailed understanding of why certain infrastructure choices can make or break the efficiency of water resource engineering projects.






## 7. Cost and Performance Analysis: Cloud vs. Local Servers

The decision between cloud and local server setups isn't just a matter of performance; it also has significant cost implications. Through our previous calculations, we've seen that while cloud instances like Azure's might seem economical at $1.30 per hour, over an extended period, like five years, the costs add up. More importantly, when you factor in the 2.5x performance hit for CPU-bound tasks like HEC-RAS modeling, the economic equation tilts heavily in favor of local servers.

Considering this performance hit, alongside data and storage latency issues inherent in cloud machines, local servers offer not only better performance but also better value for money. They handle operations faster and more efficiently, leading to shorter project timelines and lower overall costs. For resource-intensive tasks typical in water resource engineering, this can mean the difference between meeting project deadlines and budget overruns.


<br/><br/>

<p align="center">
  <img src="img/Slide4.PNG" alt="Slide 4" style="border: 2px solid black;"/>
</p>

<br/><br/>


<br/><br/>

<p align="center">
  <img src="img/Slide5.PNG" alt="Slide 5" style="border: 2px solid black;"/>
</p>

<br/><br/>


## 8. Compute Cost using Previous Case Study (West Fork Calcasieu)

In this case study, we'll apply our findings on cloud computing costs to the real-world scenario of the West Fork Calcasieu project. This analysis will include detailed cost comparisons between cloud-based and local server setups, incorporating all the factors discussed previously, including the performance impacts and practical implications.

**Part 1: Setting the Stage for Analysis**

The West Fork Calcasieu project, a significant initiative in water resources engineering, provides an excellent framework to evaluate the economic and performance aspects of cloud vs. local compute solutions. For this analysis, we consider the tasks involved in the project, such as hydrologic and hydraulic modeling, and assess the costs associated with running these tasks on Azure cloud instances versus local servers.

**Initial Parameters and Assumptions:**

- The project involves various modeling tasks, including operations in RASMAPPER and HEC-RAS.
- We consider different Azure instances: FSV2 (Windows) and F16s v2 (Linux).
- The costs are calculated based on on-demand pricing for these instances.
- We also consider the adjusted scenario where cloud instances are approximately 2.5 times slower than high-performance local machines, impacting the runtime and consequently, the cost.

**Original Cost Analysis:**

We initially calculated the costs for both parallel and non-parallel approaches using standard Azure instance pricing, without accounting for the performance hit.

**Adjusted Cost Analysis for Slower Cloud Performance:**

Recognizing that cloud instances run at a slower pace, we recalculated the costs by adjusting the runtime by a factor of 2.5. This adjustment reflects the real-world scenario where cloud servers, due to various factors like slower clock speeds and infrastructure overhead, offer reduced performance compared to local high-performance machines.

**Part 2: Detailed Cost Comparisons and Implications**

Continuing our deep dive into the cost analysis, let's examine the specific cost tables derived from our earlier calculations. These tables encapsulate the costs for using Azure cloud instances versus local compute options, considering both original and adjusted scenarios for slower cloud performance.

**Original Cost Analysis: Without Adjusting for Slower Cloud Performance**

Here, we initially assessed the costs using the standard Azure instance pricing:

| Compute Option                | Approach      | On-Demand Cost (USD) |
| ----------------------------- | ------------- | --------------------- |
| Azure FSV2 (Windows)          | Parallel      | $46.38                |
| Azure FSV2 (Windows)          | Non-Parallel  | $535.15               |
| Azure F16s v2 (Linux)         | Parallel      | $24.11                |
| Azure F16s v2 (Linux)         | Non-Parallel  | $278.26               |
| Local Compute (Windows)       | Parallel      | $6.33 (Amortized)     |
| Local Compute (Windows)       | Non-Parallel  | $73.00 (Amortized)    |

**Adjusted Cost Analysis: Accounting for 2.5x Slower Cloud Performance**

Recognizing the performance limitations of cloud instances, we recalculated the costs by adjusting the runtime by a factor of 2.5:

| Compute Option                | Approach      | Adjusted Cost (USD) |
| ----------------------------- | ------------- | --------------------  |
| Azure FSV2 (Windows)          | Parallel      | $115.94               |
| Azure FSV2 (Windows)          | Non-Parallel  | $1337.87              |
| Azure F16s v2 (Linux)         | Parallel      | $60.29                |
| Azure F16s v2 (Linux)         | Non-Parallel  | $695.65               |
| Local Compute (Windows)       | Parallel      | N/A                   |
| Local Compute (Windows)       | Non-Parallel  | N/A                   |

These are idealized scenarios, which do not include the cost of storage, network data costs, licensing, cloud consulting and implementation cost, etc.  

Generally, the poor performance of cloud resources leads to an oversubscription of resources in an attempt to reduce runtimes.  This leads to even higher costs than the idealized scenario above.  The most inefficient configurations are typically the large Azure instances offering up to 48 to 96 VCPU's and a large pool of memory as a single instance.  Unfortunately, these types of instances are routinely recommended by IT professional who are accustomed to more cloud and web-oriented software due to the dominance of Software as a Service (SaaS) models have become predominant in so many fields of software development.  Unfortunately, this industry progression and optimization actually moves further away from the optimal setup for a GIS user or Flood Modeler using HEC-RAS, and leads to many engineering firms making uninformed decisions about their infrastrucure platforms, hamstringing their employees with runtimes that are significantly slower than a midrange deskop (despite a price that is more suggestive of a specialized HPC solution).     

**Analysis of the Cost Tables:**

The stark contrast in costs between cloud-based and local computing solutions becomes evident when we account for the slower performance of cloud servers. The adjusted costs for cloud instances, particularly for non-parallel approaches, are significantly higher than those for local compute options. This discrepancy highlights the economic inefficiencies of relying on cloud infrastructure for tasks that require intensive computing power and frequent data transactions, typical in water resource engineering projects like the West Fork Calcasieu.

The local compute option, even when using the spot instance pricing for comparison, offers a more economical and efficient solution. It outperforms cloud solutions not only in terms of cost but also in the absence of performance limitations.

**Implications for Water Resources Engineering Projects:**

This case study underscores a crucial consideration for engineering projects: the need to balance cost and performance when choosing between cloud and local infrastructure. While cloud systems offer scalability and accessibility, they may not always be the most cost-effective or efficient choice for specific engineering tasks, particularly those involving intensive GIS operations and HEC-RAS modeling.

In conclusion, the West Fork Calcasieu project case study provides a clear, quantitative perspective on the economic and performance trade-offs of cloud vs. local computing. It serves as a guide for water resource engineers and decision-makers, emphasizing the importance of a nuanced approach to infrastructure choices, one that aligns with the specific demands and objectives of each project.

## Conclusion: Navigating the Crossroads of Cloud and Local Computing in Water Resource Engineering

As we conclude our exploration of the West Fork Calcasieu project and its broader implications, it becomes evident that the journey from a 10x to a 0.25x engineer is not just a theoretical concept but a stark reality in the realm of water resources engineering. The case study offers more than just numbers; it provides a narrative about the critical decisions facing our industry today.

**Key Takeaways:**

- **Performance and Cost Efficiency:** The dramatic contrast in performance and cost between cloud and local computing underscores a fundamental challenge. While cloud computing brings scalability and accessibility, it often comes at the cost of reduced efficiency and increased expenses, especially for tasks integral to water resources engineering, like GIS operations and HEC-RAS modeling.
- **The 10x to 0.25x Transition:** Our analysis reveals how reliance on less efficient cloud infrastructure, combined with the abandonment of AI and advanced tools like HEC-Commander, can drastically reduce an engineer's productivity. This shift from 10x to 0.25x efficiency is not just a metric change; it represents a significant impact on project outcomes, timelines, and overall engineering effectiveness.
- **A Balanced Approach:** The decision to choose between cloud and local computing should not be a binary one. Instead, it calls for a balanced, nuanced approach, taking into account the specific demands of each project, the nature of the tasks involved, and the long-term economic implications.

<br/><br/>

<p align="center">
  <img src="img/Slide10.PNG" alt="Slide 10" style="border: 2px solid black;"/>
</p>

<br/><br/>


**Looking Ahead:**

As water resource engineers, we stand at a crossroads. The decisions we make today about our computational infrastructure will shape not only our current projects but also the future trajectory of our field. It's imperative that we approach these decisions with a clear understanding of their implications – not just for efficiency and cost but also for the quality and reliability of our engineering solutions.

**A Call to Action:**

This case study and analysis serve as a call to action for the engineering community. We must critically assess the tools and technologies at our disposal, understand their strengths and limitations, and make informed decisions that align with our project goals and professional values. Potentially rendering your talent pool from a group of 10x engineers to 0.25x engineers can be done quite easily by simply following the current industry trends without taking a data-driven approach.

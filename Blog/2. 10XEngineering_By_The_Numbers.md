# From 10x to 0.25x Engineering: By The Numbers

10x Engineering with AI: By the Numbers
Introduction
This is a follow-up to my previous post about 10x engineering and water resources. The shrewd reader who looked at the numbers should have come away asking, “You only use 10 machines. How did you get a greater than 10x speed improvement?” It's a valid question that highlights the core of 10x engineering - not just scaling up resources, but also optimizing them with a data-driven approach.  The foundation of this approach was benchmarking large 2D HEC-RAS models to understand how they scale

Fenstermaker's local compute cluster was utilized as a baseline, and runtimes for the benchmark model were converted to unit runtimes.  This allows a direct comparison across platforms with greater unit runtimes denoting slower overall model performance, and lower unit runtimes indicating faster overall model performance.  These findings are summarized on the slide below:


<p align="center">
  <img src="img/Slide2.PNG" alt="Slide 2" style="border: 2px solid black;"/>
</p>


# Linear vs Nonlinear Scaling
To optimize for throughput in a parallelized scenario, the number of paralell runs per machine (and core count) should maximize efficiency.  In the slide above, it is apparent that runs at 1 core or 2 cores have very similar efficiency.  This is due to the internal architecture of the chips, L3 cache sharing, etc.  After 2 cores, adding more cores causes a large drop in overall efficiency.  Therefore, where throughput is a priority, a 2 core configuration was used.  This strategy is described in the slide below as giving 70% to gain 70%: 


<br/><br/>

<p align="center">
  <img src="img/Slide6.PNG" alt="Slide 6" style="border: 2px solid black;"/>
</p>

This demonstrates that the power of parallelization is not just in the ability to run multiple plans at once, but to also optimize efficiency. 

<br/><br/>
# Insights on Efficiency Optimization
By optimizing the core count and parallelizing just 3 runs per machine, up to 70% greater throughput per machine was achieved for throughput-dependent worlflows.  This configuration also leaves spare capacity for the user to perform other operations without significant slowdonw.  This scaling and efficiency relationship has been consistently demonstrated across many 2D HEC-RAS models of varying size, complexity and stages of model development, and is fundamentally linked to the types of mathematical operations being performed and how the data is synced across cores. 

* By maximizing single core clock speed, the linear scaling was maximized, lowering unit runtime.  

* By maximizing efficiency with 2-core runs and paralellization, an additional 70% throughput per machine was realized.  

The impact of clock speed on overall performance will be apparent in the sections below, where a typical midrange desktop and cloud options unit runtimes are compared with an optimized local compute cluster.  


<br/><br/>

<p align="center">
  <img src="img/CloudProblems.jpg" alt="CloudProblems.jpg" style="border: 2px solid black;"/>
</p>

<br/><br/>

# Local Compute vs Cloud Costs

## 1. Introduction to Benchmarking and Data Driven Analysis

In addition to the previously noted benchmarking model, detailed modeling was conducted on a wide range of publicly available cloud systems.  This included opening, closing and saving 2D HEC-RAS projects, as well as performing common RASMapper geometry and terrain operations.  This real-world testing is a better measure than the synthetic testing or promised specifications/performance from vendors.  

## 2. The Latency Impact of Cloud Systems on GIS Operations

A critical aspect contributing to this downturn is the inherent latency issues in cloud systems, which significantly impede GIS operations. For water resource engineers, tools like RASMAPPER are essential. However, benchmarking reveals that operations within RASMAPPER – including opening, closing, saving, and editing terrains – are 20-80% slower on cloud systems, averaging around a 60% reduction in performance. This slowdown isn't just a minor inconvenience; it's a substantial barrier for any serious large-scale work on these platforms.  This 60% reduction in performance, compounded by user interface delays, creates a ripple effect. Tasks that were once quick and efficient become drawn-out ordeals, significantly impacting project timelines and productivity on even the fastest available cloud storage systems. The impact is not just felt in the time taken to complete these tasks but also in the quality of work. Engineers, bogged down by sluggish systems, are unable to perform at their best, leading to a cascading effect on overall project outcomes.



## 3. Local vs. Cloud Infrastructure for 2D HEC-RAS

When it comes to HEC-RAS modeling, the choice between local and cloud infrastructure becomes critical. Local setups, even those as simple as a workstation with a USB-C hard drive, generally outperform their cloud counterparts for these specific tasks. 

Public cloud infrastructures, despite their massive scale and resources, consistently fall short in meeting the unique demands of HEC-RAS, RASMapper and 2D models. The scale efficiencies of cloud systems, often touted as their biggest advantage, are achieved through specific approaches that don't match well with HEC-RAS's 2D compute requirements.  This is primarily due to the low clock speeds typically available, and the limited thermal footprint available in cloud facilities at scale.  This drives cloud providers to select hardware platforms and CPU die packages that take advantage of the nonlinear relationship between per-cycle efficiency, core voltage and clock speed, always resulting in lower overall clock speeds per CPU core.  This allows for a greater number of cores to be added per GHZ of base clock frequency that is traded off.  For vendors that sell VCPU's, there is also a great financial incentive built into their hardware platform selection which is reprsented in the customer-facing public cloud options.  

When CPU's are not being placed in an arrangement where thermal density and core count are not being maximized, better performance characteristics are observed for single-thread-dependent applications, which still comprise the majority of water resources workflows.  In addition, other shared infrastructure such as storage, memory, VM overhead and the "noisy neighbor" effect compound these inefficiencies.  This is evident when testing consumer-grade desktops with equivalent cloud instances on the same chipset generation, and observing that the desktop consistently outperforms, even when adjusted for lower clock speeds.  

 <br/><br/>

<p align="center">
  <br/>Slide:<br/>
  <img src="img/Slide3.PNG" alt="Slide 3" style="border: 2px solid black;"/>
</p>

<br/><br/>

 ## "Elastic" Storage Behavior 
 
ELASTIC STORAGE BEHAVIOR HERE.  SEARCH COMMAND LINE IS ALL YOU NEED IN KNOWLEDGE BASE FOR ELASTIC STORAGE


For tasks like RASMAPPER operations and HEC-RAS modeling, which involve frequent, small-scale data read/write operations, these performance costs can be particularly burdensome, leading to significant inefficiencies.



## 4. Latency Challenges for GIS Workflows in the Cloud

The inefficiencies of cloud infrastructure become even more pronounced when examining the workflows common in GIS operations. These workflows often involve numerous small, frequent data transactions – a type of operation that cloud systems are not optimized for. HEC-RAS modeling, which lacks GPU acceleration and is heavily reliant on sequential data access, is notably ill-suited for the cloud environment.

This mismatch leads to a marked decrease in efficiency. What might be a routine operation on a local setup becomes a sluggish and frustrating process on the cloud. This not only slows down the overall workflow but also impacts the quality of the modeling work. The lag in processing and data handling can lead to delays in decision-making and, in some cases, compromise the accuracy of the models due to truncated or rushed analysis.

The implications of these challenges are profound. They not only affect the day-to-day work of engineers but also have broader implications for project timelines, costs, and ultimately the effectiveness of water resource management strategies.  While tools do exist to help ameliorate these limitations and optimize workflows and data types for the cloud, a windows desktop-based virtual machine running QGIS or ArcGIS Pro typically does not benefit from those optimizations.  RASMapper also suffers from the same limitations, with most operations being totally single-threaded.  HDF file access patterns exhibit the same sensitivity to storage latency as geometry, terrain and map layer operations, rendering them difficult to transition to cloud-based platforms without significant performance impacts.  

## 5. Industry Trends vs. Practical Insights

Despite the growing trend towards cloud adoption in various sectors, including water resources engineering, practical experiences paint a different picture. Specifically, for HEC-RAS modeling, the movement towards cloud infrastructure appears to be more of a step backward than forward. This viewpoint is not just based on theoretical assumptions but is rooted in real-world experiences and extensive benchmarking.

As someone deeply embedded in the industry, I offer these insights not just as observations but as a caution to my fellow professionals and LinkedIn followers. The allure of cloud computing, with its promise of scalability and ease of access, can be tempting. However, it's crucial to assess the suitability of these systems for specific applications like HEC-RAS modeling. Blind adoption of cloud solutions, without considering their impact on productivity and project outcomes, can lead to significant setbacks.


<br/><br/>

<p align="center">
  <img src="img/Slide4.PNG" alt="Slide 4" style="border: 2px solid black;"/>
</p>

<br/><br/>

Given this comparison, it is clear just from the unit runtimes that even the best public cloud is up to 1.5x slower on a unit runtime basis, due to slower clock speeds and cloud-infrastructure related overhead and thermal profile.  While runtimes converged when the local compute was being used poorly, it should be noted that this comparison is between a cloud Linux instance and a local Windows instance, and a consistent 15% advantage was observed across all hardware configurations when the Linux solver was used vs the Windows solver.  With all 24 local cores engaged, hyperthreading enabled, and the die reaching thermal saturation, the performance of the two platforms coverged.  This is where most users using "All Cores" without any special CPU optimizations are running, and with that configuration one may not even notice a difference between platforms from a performance perspective.  


<br/><br/>

<p align="center">
  <img src="img/Slide5.PNG" alt="Slide 5" style="border: 2px solid black;"/>
</p>

<br/><br/>




## 6. Deep Dive into Performance and Benchmarking

The performance issues with cloud systems are not mere speculation; they are confirmed by thorough benchmarking. Various models, especially large 2D models in HEC-RAS, consistently demonstrate performance issues when operated on cloud platforms. The primary culprit is large matrix operations, which are integral to these models but are handled inefficiently by cloud servers.

These benchmarking exercises reveal a consistent pattern: cloud systems, regardless of their configurations or the scale of resources thrown at them, struggle with the computational demands of large-scale water resource models. The performance hit is not marginal but substantial, leading to significantly extended project timelines and increased costs.

In future discussions, I plan to delve deeper into the specifics of these benchmarking efforts. We'll explore the nuances of scaling, efficiency, and performance in both cloud and local server environments. This will provide a more detailed understanding of why certain infrastructure choices can make or break the efficiency of water resource engineering projects.






## 7. Cost and Performance Analysis: Cloud vs. Local Servers

The decision between cloud and local server setups isn't just a matter of performance; it also has significant cost implications. Through our previous calculations, we've seen that while cloud instances like Azure's might seem economical at $1.30 per hour, over an extended period, like five years, the costs add up. More importantly, when you factor in the 2.5x performance hit for CPU-bound tasks like HEC-RAS modeling, the economic equation tilts heavily in favor of local servers.

Considering this performance hit, alongside data and storage latency issues inherent in cloud machines, local servers offer not only better performance but also better value for money. They handle operations faster and more efficiently, leading to shorter project timelines and lower overall costs. For resource-intensive tasks typical in water resource engineering, this can mean the difference between meeting project deadlines and budget overruns.





## 8. Compute Cost using Previous Case Study (West Fork Calcasieu)

In this case study, we'll apply our findings on cloud computing costs to the real-world scenario of the West Fork Calcasieu project. This analysis will include detailed cost comparisons between cloud-based and local server setups, incorporating all the factors discussed previously, including the performance impacts and practical implications.

**Part 1: Setting the Stage for Analysis**

The West Fork Calcasieu project, a significant initiative in water resources engineering, provides an excellent framework to evaluate the economic and performance aspects of cloud vs. local compute solutions. For this analysis, we consider the tasks involved in the project, such as hydrologic and hydraulic modeling, and assess the costs associated with running these tasks on Azure cloud instances versus local servers.

**Initial Parameters and Assumptions:**

- The project involves various modeling tasks, including operations in RASMAPPER and HEC-RAS.
- We consider different Azure instances: FSV2 (Windows) and F16s v2 (Linux).
- The costs are calculated based on on-demand pricing for these instances.
- We also consider the adjusted scenario where cloud instances are approximately 2.5 times slower than high-performance local machines, impacting the runtime and consequently, the cost.

**Original Cost Analysis:**

We initially calculated the costs for both parallel and non-parallel approaches using standard Azure instance pricing, without accounting for the performance hit.

**Adjusted Cost Analysis for Slower Cloud Performance:**

Recognizing that cloud instances run at a slower pace, we recalculated the costs by adjusting the runtime by a factor of 2.5. This adjustment reflects the real-world scenario where cloud servers, due to various factors like slower clock speeds and infrastructure overhead, offer reduced performance compared to local high-performance machines.

**Part 2: Detailed Cost Comparisons and Implications**

Continuing our deep dive into the cost analysis, let's examine the specific cost tables derived from our earlier calculations. These tables encapsulate the costs for using Azure cloud instances versus local compute options, considering both original and adjusted scenarios for slower cloud performance.

**Original Cost Analysis: Without Adjusting for Slower Cloud Performance**

Here, we initially assessed the costs using the standard Azure instance pricing:

| Compute Option                | Approach      | On-Demand Cost (USD) |
| ----------------------------- | ------------- | --------------------- |
| Azure FSV2 (Windows)          | Parallel      | $46.38                |
| Azure FSV2 (Windows)          | Non-Parallel  | $535.15               |
| Azure F16s v2 (Linux)         | Parallel      | $24.11                |
| Azure F16s v2 (Linux)         | Non-Parallel  | $278.26               |
| Local Compute (Windows)       | Parallel      | $6.33 (Amortized)     |
| Local Compute (Windows)       | Non-Parallel  | $73.00 (Amortized)    |

**Adjusted Cost Analysis: Accounting for 2.5x Slower Cloud Performance**

Recognizing the performance limitations of cloud instances, we recalculated the costs by adjusting the runtime by a factor of 2.5:

| Compute Option                | Approach      | Adjusted Cost (USD) |
| ----------------------------- | ------------- | --------------------  |
| Azure FSV2 (Windows)          | Parallel      | $115.94               |
| Azure FSV2 (Windows)          | Non-Parallel  | $1337.87              |
| Azure F16s v2 (Linux)         | Parallel      | $60.29                |
| Azure F16s v2 (Linux)         | Non-Parallel  | $695.65               |
| Local Compute (Windows)       | Parallel      | N/A                   |
| Local Compute (Windows)       | Non-Parallel  | N/A                   |

These are idealized scenarios, which do not include the cost of storage, network data costs, licensing, cloud consulting and implementation cost, etc.  

Generally, the poor performance of cloud resources leads to an oversubscription of resources in an attempt to reduce runtimes.  This leads to even higher costs than the idealized scenario above.  The most inefficient configurations are typically the large Azure instances offering up to 48 to 96 VCPU's and a large pool of memory as a single instance.  Unfortunately, these types of instances are routinely recommended by IT professional who are accustomed to more cloud and web-oriented software due to the dominance of Software as a Service (SaaS) models have become predominant in so many fields of software development.  Unfortunately, this industry progression and optimization actually moves further away from the optimal setup for a GIS user or Flood Modeler using HEC-RAS, and leads to many engineering firms making uninformed decisions about their infrastrucure platforms, hamstringing their employees with runtimes that are significantly slower than a midrange deskop (despite a price that is more suggestive of a specialized HPC solution).     

**Analysis of the Cost Tables:**

The stark contrast in costs between cloud-based and local computing solutions becomes evident when we account for the slower performance of cloud servers. The adjusted costs for cloud instances, particularly for non-parallel approaches, are significantly higher than those for local compute options. This discrepancy highlights the economic inefficiencies of relying on cloud infrastructure for tasks that require intensive computing power and frequent data transactions, typical in water resource engineering projects like the West Fork Calcasieu.

The local compute option, even when using the spot instance pricing for comparison, offers a more economical and efficient solution. It outperforms cloud solutions not only in terms of cost but also in the absence of performance limitations.

**Implications for Water Resources Engineering Projects:**

This case study underscores a crucial consideration for engineering projects: the need to balance cost and performance when choosing between cloud and local infrastructure. While cloud systems offer scalability and accessibility, they may not always be the most cost-effective or efficient choice for specific engineering tasks, particularly those involving intensive GIS operations and HEC-RAS modeling.

In conclusion, the West Fork Calcasieu project case study provides a clear, quantitative perspective on the economic and performance trade-offs of cloud vs. local computing. It serves as a guide for water resource engineers and decision-makers, emphasizing the importance of a nuanced approach to infrastructure choices, one that aligns with the specific demands and objectives of each project.

## Conclusion: Navigating the Crossroads of Cloud and Local Computing in Water Resource Engineering

As we conclude our exploration of the West Fork Calcasieu project and its broader implications, it becomes evident that the journey from a 10x to a 0.25x engineer is not just a theoretical concept but a stark reality in the realm of water resources engineering. The case study offers more than just numbers; it provides a narrative about the critical decisions facing our industry today.

**Key Takeaways:**

- **Performance and Cost Efficiency:** The dramatic contrast in performance and cost between cloud and local computing underscores a fundamental challenge. While cloud computing brings scalability and accessibility, it often comes at the cost of reduced efficiency and increased expenses, especially for tasks integral to water resources engineering, like GIS operations and HEC-RAS modeling.
- **The 10x to 0.25x Transition:** Our analysis reveals how reliance on less efficient cloud infrastructure, combined with the abandonment of AI and advanced tools like HEC-Commander, can drastically reduce an engineer's productivity. This shift from 10x to 0.25x efficiency is not just a metric change; it represents a significant impact on project outcomes, timelines, and overall engineering effectiveness.
- **A Balanced Approach:** The decision to choose between cloud and local computing should not be a binary one. Instead, it calls for a balanced, nuanced approach, taking into account the specific demands of each project, the nature of the tasks involved, and the long-term economic implications.

<br/><br/>

<p align="center">
  <img src="img/Slide10.PNG" alt="Slide 10" style="border: 2px solid black;"/>
</p>

<br/><br/>


**Looking Ahead:**

As water resource engineers, we stand at a crossroads. The decisions we make today about our computational infrastructure will shape not only our current projects but also the future trajectory of our field. It's imperative that we approach these decisions with a clear understanding of their implications – not just for efficiency and cost but also for the quality and reliability of our engineering solutions.

**A Call to Action:**

This case study and analysis serve as a call to action for the engineering community. We must critically assess the tools and technologies at our disposal, understand their strengths and limitations, and make informed decisions that align with our project goals and professional values. Potentially rendering your talent pool from a group of 10x engineers to 0.25x engineers can be done quite easily by simply following the current industry trends without taking a data-driven approach.

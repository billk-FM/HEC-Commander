# Benchmarking Is All You Need
### A Data-Driven Approach to Optimizing HEC-RAS Performance 
 
<p align="center">
 <img src="img/biayn-logo.png" alt="AI-Generated Image of Bootleggers on an Airboat under the Pontchartrain Expressway, while a semi truck absurdly treads water behind them" style="border: 2px solid black; width: 50%;"/><br></br>
 <i>You Wanna Run this Bayou Hot Rod for Pink Slips?</i>

 
</p>


## I. Introduction

The performance of our computational platforms can make or break a project. Among these tools, the Hydrologic Engineering Center's River Analysis System (HEC-RAS) stands out as a critical resource for modeling river hydraulics. However, as models grow in size and complexity, the computational demands can quickly outpace the capabilities of generic hardware setups. This is where benchmarking comes in.

At Fenstermaker, we've made it a priority to take a data-driven approach to optimizing our HEC-RAS workflows. By systematically benchmarking HEC-RAS performance across a range of hardware and software configurations, we've gained invaluable insights into the factors that truly drive performance. This blog post will dive into our methodology, results, and the implications for water resources engineering projects.

## II. Methodology

The foundation of any good benchmarking study is a representative test case. For our purposes, we selected a large, complex 2D HEC-RAS model that typifies the sort of computational challenges we regularly encounter. This benchmark model was then tested across a variety of platforms, including our in-house local compute clusters and popular public cloud systems like Microsoft Azure and Amazon Web Services (AWS).

To ensure a fair and direct comparison between these diverse platforms, we converted all of our benchmark results into a standardized "unit runtime" metric. This normalization process allowed us to cut through the noise of different hardware specifications and focus on the relative performance of each setup.

## III. Results and Analysis

### A. Core scaling and efficiency

One of the most striking findings from our benchmarking was the importance of core count and parallel processing strategy. We found that for most HEC-RAS workloads, optimal performance was achieved by running 3 parallel simulations, each utilizing 2 cores. This "3x2" setup consistently delivered the best balance of throughput and efficiency.

Interestingly, we noticed a significant drop-off in efficiency when moving beyond 2 cores per simulation. This highlights the importance of understanding the specific computational characteristics of HEC-RAS and tailoring our hardware setups accordingly.

### B. Local compute vs. public cloud performance

Another key area of investigation was the relative performance of local compute clusters versus public cloud instances. Across the board, we found that optimized local workstations outperformed cloud-based setups for the sort of single-threaded, I/O-bound operations that are common in HEC-RAS.

Even the best-performing cloud instances, such as the AWS C6i, were around 1.5 times slower than an equivalent local workstation on a per-core basis. Other major cloud providers fared even worse, with instances up to 2.5 times slower than our local cluster.

Interestingly, we did observe a convergence in performance when our local cluster was intentionally hobbled to mimic suboptimal configurations (e.g., with hyperthreading enabled). This suggests that the performance advantages of local compute are contingent on proper hardware and software tuning.

### C. Hardware and software optimization

Building on the above findings, we delved into the specific hardware and software optimizations that yield the best HEC-RAS performance. On the hardware front, we found that disabling hyperthreading and Intel's "efficiency" cores provided a consistent boost. On top of this, the use of Intel's Extreme Tuning Utility (XTU) yielded an additional 10% improvement.

In terms of core count, our benchmarks showed that 8 cores tend to be the sweet spot for HEC-RAS performance on local workstations. This 8-core setup, when paired with the above optimizations, regularly outperformed even the heftiest cloud instances.

## IV. Implications for Water Resources Engineering Projects

So, what does all of this mean for real-world water resources engineering projects? At the most basic level, it underscores the importance of treating computational performance as a first-class engineering concern. The speed and efficiency of our HEC-RAS simulations directly impact our ability to deliver timely, high-quality results.

More specifically, our benchmarking results suggest that a properly optimized local compute cluster can offer significant performance advantages over default hardware setups or cloud-based instances. By understanding the specific performance characteristics of HEC-RAS and tailoring our hardware and software stacks accordingly, we can unlock new levels of productivity and capability.

## V. Cost Analysis

Of course, performance is only one side of the equation. For any engineering organization, cost is an equally important consideration. To assess the financial implications of our benchmarking results, we conducted a thorough cost analysis.

On the local compute side, we amortized the upfront cost of our optimized workstations over a 5-year expected lifespan. This worked out to an effective hourly rate of around $0.17 per core.

In contrast, the hourly costs for equivalent cloud instances were significantly higher. Even with reserved instance pricing, the best-performing cloud setups came in at around $1.30 to $1.45 per core-hour. When adjusted for the performance differential we observed in our benchmarks, the effective cost of cloud computing for HEC-RAS workloads was even higher.

This cost analysis paints a compelling picture. For the vast majority of HEC-RAS use cases, a well-optimized local compute cluster offers not just the best performance, but also the most cost-effective solution.

## VI. Conclusion

As we've seen throughout this post, benchmarking is all you need when it comes to optimizing HEC-RAS performance. By taking a systematic, data-driven approach to evaluating hardware and software setups, we can identify the configurations that truly maximize our computational capabilities.

For Fenstermaker, this benchmarking process has resoundingly affirmed the value of optimized local compute clusters. By tailoring our workstations to the specific needs of HEC-RAS, we've been able to achieve levels of performance and efficiency that simply aren't possible with stock hardware or cloud-based instances.

Looking forward, we believe that this sort of rigorous benchmarking should be a standard part of any water resources engineering workflow. As our models continue to grow in size and complexity, the ability to efficiently leverage computational resources will only become more critical.

## VII. Appendices

For those interested in diving deeper into our benchmarking process and results, we've included several appendices to this post:

- Appendix A provides a detailed breakdown of our benchmark results across all tested platforms and configurations.
- Appendix B offers a closer look at the specific hardware and software specs we used in our testing.
- Appendix C includes a collection of additional resources and guides for optimizing HEC-RAS performance.

We hope that this post has been informative and illuminating. As always, if you have any questions, comments, or insights to share, please don't hesitate to reach out. At Fenstermaker, we're committed to advancing the state of the art in water resources engineering, and we believe that collaboration and knowledge-sharing are essential to that mission.

## Benchmarking Results: A Visual Exploration

To really drive home the insights from our benchmarking process, we've prepared a series of visualizations that highlight key trends and takeaways. Let's dive in.

### Image 1: Machine Performance by Core Count

<p align="center">
 <img src="img/biayn-1_curves.png" alt="Runtime Curves (Runtime vs Core Count)" style="border: 2px solid black; width: 75%;"/>
</p>

This chart shows the runtime performance of various machines across a range of core counts. A few key observations:

- Performance improves (i.e., runtime decreases) as core count increases, but with diminishing returns.
- The performance curves are not linear, with most machines showing a significant change in slope around the 2-4 core mark.
- The relative ranking of machines remains fairly consistent across core counts, with the Fenstermaker HPC clusters and the Dell Precision workstation leading the pack.

### Image 2: CPU Unit Effort at 1 Core

<p align="center">
 <img src="img/biayn-2_uniteffort_1core.png" alt="CPU Unit Effort at 1 Core" style="border: 2px solid black; width: 75%;"/>
</p>

Switching gears, this chart looks at the CPU unit effort expended by each machine when running on a single core. This metric provides a way to compare the inherent single-threaded performance of each CPU, independent of core count.

- The Fenstermaker HPC cluster, with its optimized 12th Gen Intel CPUs, demonstrates the lowest unit effort (i.e., highest performance).
- The Dell rack server and Hyper-V VM, both running older AMD CPUs, show significantly higher unit efforts.
- Interestingly, the AWS and Azure cloud instances, despite running on newer Intel and AMD hardware, fail to match the performance of the optimized Fenstermaker cluster.

### Image 3: CPU Unit Effort at Lowest Runtime

<p align="center">
 <img src="img/biayn-3_uniteffort_besttimes.png" alt="CPU Unit Effort at Lowest Runtime" style="border: 2px solid black; width: 75%;"/>
</p>

Building on the previous chart, this visual shows the CPU unit effort at each machine's lowest observed runtime, regardless of core count.

- The broad trends remain similar, with the Fenstermaker cluster and Dell workstation in the lead.
- However, the gaps between machines are smaller than in the single-core scenario, reflecting the performance benefits of higher core counts.
- Notably, even at their respective optimal core counts, the cloud instances still lag behind the top on-premises performers.

### Image 4: Unit Runtimes at 1 Core

<p align="center">
 <img src="img/biayn-4_unitruntime_1core.png" alt="Unit Runtimes at 1 Core" style="border: 2px solid black; width: 75%;"/>
</p>

Circling back to unit runtimes, this chart ranks each machine based on its performance at a single core.

- The Fenstermaker HPC cluster, in both its "Hardware Defaults" and "Optimized" configurations, claim the top spots.
- The Dell servers and the majority of cloud instances cluster around the middle of the pack.
- The Midrange Laptop, despite its portability advantage, brings up the rear in terms of raw single-core performance.

### Image 5: Unit Runtimes at Lowest Runtime

<p align="center">
 <img src="img/biayn-5_unitruntime_besttimes.png" alt="Image 5: Unit Runtimes at Lowest Runtime" style="border: 2px solid black; width: 75%;"/>
</p>

Finally, we have the unit runtime ranking at each machine's optimal core count.

- The Fenstermaker HPC cluster maintains its lead, with the optimized configuration stretching its advantage.
- The Dell Precision workstation makes a strong showing, nearly matching the base Fenstermaker cluster.
- The cloud instances, while improving on their single-core showing, still struggle to keep pace with the leaders.

Taken together, these visualizations reinforce the key findings of our benchmarking analysis. They highlight the performance advantages of optimized, on-premises hardware, particularly for the sort of single-threaded, I/O-bound workloads that are common in HEC-RAS modeling. At the same time, they underscore the importance of configuration and tuning in extracting maximum performance from any given hardware platform.


# Detailed Benchmarking Information

















###  Reproducing Unit Calculations and Plots

<details>
<summary>Full Python Code for Reproducing Dataframes and Plots (Click to Expand)</summary>

```
import pandas as pd
import matplotlib.pyplot as plt

def load_data(performance_file, machine_names_file):
    """
    Load performance data and machine names from CSV files.
    
    Parameters:
    - performance_file: Path to the CSV file containing performance data.
    - machine_names_file: Path to the CSV file containing machine names.
    
    Returns:
    - A DataFrame merging both the performance data and machine names.
    """
    performance_data = pd.read_csv(performance_file)
    machine_names = pd.read_csv(machine_names_file)
    merged_data = pd.merge(performance_data, machine_names, on='Machine Index')
    display(merged_data)
    return merged_data

def plot_performance_data(merged_data):
    """
    Plot the performance data showing runtime against number of cores for each machine.
    
    Parameters:
    - merged_data: DataFrame containing the merged performance data and machine names.
    """
    fig, ax = plt.subplots(figsize=(17, 6))

    for machine_name, group in merged_data.groupby('Machine Name'):
        ax.plot(group['Cores'], group['Runtime (min)'], marker='o', linestyle='-', label=machine_name)

    ax.set_xlabel('Number of Cores', fontsize=14)
    ax.set_ylabel('Runtime (minutes)', fontsize=14)
    ax.set_title('Machine Performance by Core Count', fontsize=16)
    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title='Machine Name')
    plt.tight_layout()
    plt.show()

def plot_unit_performance_data(merged_data):
    """
    Plot the performance data showing unit runtime against number of cores for each machine.
    
    Parameters:
    - merged_data: DataFrame containing the merged performance data and machine names.
    """
    fig, ax = plt.subplots(figsize=(17, 6))

    for machine_name, group in merged_data.groupby('Machine Name'):
        ax.plot(group['Cores'], group['Unit Runtime'], marker='o', linestyle='-', label=machine_name)

    ax.set_xlabel('Number of Cores', fontsize=14)
    ax.set_ylabel('Unit Runtime', fontsize=14)
    ax.set_title('Machine Performance by Core Count', fontsize=16)
    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title='Machine Name')
    plt.tight_layout()
    plt.show()    

def main():
    performance_file = 'performance_data.csv'
    machine_names_file = 'machine_names.csv'
    merged_data = load_data(performance_file, machine_names_file)
    plot_performance_data(merged_data)

if __name__ == '__main__':
    main()

    performance_file = 'performance_data.csv'
    machine_names_file = 'machine_names.csv'
    merged_data = load_data(performance_file, machine_names_file)

    # Now, provide the same plot, but only include up to 24 cores.
    merged_data_24 = merged_data[merged_data['Cores'] <= 20]
    if not merged_data_24.empty:
        plot_performance_data(merged_data_24)
    else:
        print("No data available for machines with 24 or fewer cores.")
    
#  Using 10.98 minutes as the baseline, we can calculate a unit runtime for each machine.
# Create a new column in the DataFrame that contains the unit runtime for each machine.
merged_data['Unit Runtime'] = merged_data['Runtime (min)'] / 35.82
display(merged_data)

# Plot unit runtimes less than 20 cores
merged_data_20 = merged_data[merged_data['Cores'] <= 20]
if not merged_data_20.empty:
    plot_unit_performance_data(merged_data_20)
else:
    print("No data available for machines with 20 or fewer cores.")




# Print a list of Machine Names and Unit Runtimes at 1 Core. Sort by unit runtime

display(merged_data[merged_data['Cores'] == 1][['Machine Name', 'Unit Runtime']].sort_values(by='Unit Runtime'))

# Make a bar chart with Unit Runtime.  Omit line 123
display(merged_data[merged_data['Cores'] == 1][['Machine Name', 'Unit Runtime']].sort_values(by='Unit Runtime').plot(kind='bar', x='Machine Name', y='Unit Runtime'))



# Create a new column "Manufacturer".  If "AMD" is in the name, label AMD, if not, Intel
merged_data['Manufacturer'] = merged_data['Machine Name'].apply(lambda x: 'AMD' if 'AMD' in x or 'EPYC' in x or 'Ryzen' in x or '7V12' in x else 'Intel')
display(merged_data)
# save to CSV
merged_data.to_csv('merged_data.csv')



# Make bar chart color if manufacturer is AMD
merged_data[merged_data['Cores'] == 1][['Machine Name', 'Unit Runtime', 'Manufacturer']].sort_values(by='Unit Runtime').plot(kind='bar', x='Machine Name', y='Unit Runtime', color=merged_data['Manufacturer'].map({'AMD': 'red', 'Intel': 'blue'}))
plt.show()

# save to new dataframe UnitRuntimes
UnitRuntimes = merged_data[merged_data['Cores'] == 1][['Machine Name', 'Unit Runtime', 'Manufacturer']].sort_values(by='Unit Runtime')

# Now, for any machines index 8 and 17, they only have data at 16 and 8 cores respectively.  
# We can divide the runtime by 10.98 to get the unit runtime, and add that line to UnitRuntimes
# Since UnitRuntimes doesn't have these entries because there are no entries for 1 core, we can add them to UnitRuntimes from merged_data

# Lookup the runtime in minutes for index 8 and 17
display(merged_data[(merged_data['Machine Index'] == 8) | (merged_data['Machine Index'] == 17)][['Machine Name', 'Cores', 'Runtime (min)']])

# use that data to calculate the unit runtime and add it to UnitRuntimes
UnitRuntimes.at[8, 'Unit Runtime'] = 1.90
UnitRuntimes.at[17, 'Unit Runtime'] = 2.83
UnitRuntimes.at[123, 'Unit Runtime'] = 1.37


# Populate the manufacturer column for these two entries
UnitRuntimes.at[8, 'Manufacturer'] = 'AMD'
UnitRuntimes.at[17, 'Manufacturer'] = 'AMD'

# Populate Machine Name and Machine Index for these two entries
UnitRuntimes.at[8, 'Machine Name'] = 'AWS c5a.8xlarge (AMD EPYC 7R32) (Linux Solver)'
UnitRuntimes.at[17, 'Machine Name'] = 'Dell Rack Machine (Hyper V AMD, 10 vCPU, 3.49GHz, 16GB RAM, 128 GB drive)'
UnitRuntimes.at[8, 'Machine Index'] = 8
UnitRuntimes.at[17, 'Machine Index'] = 17

# Sort data by Unit Runtime
UnitRuntimes = UnitRuntimes.sort_values(by='Unit Runtime')

#save to UnitRuntimes.csv
UnitRuntimes.to_csv('UnitRuntimes.csv')


import matplotlib.pyplot as plt

# Assuming merged_data is your DataFrame with the same structure as the UnitRuntimes.csv
# First, sort the data by 'Unit Runtime' to make the chart organized
sorted_merged_data = UnitRuntimes.sort_values('Unit Runtime')
display(sorted_merged_data)

# Now, plotting all machines with a horizontal bar chart
plt.figure(figsize=(10, len(sorted_merged_data) / 1.5))  # Adjusting figure size based on number of entries
plt.barh(sorted_merged_data['Machine Name'], sorted_merged_data['Unit Runtime'], color=sorted_merged_data['Manufacturer'].map({'AMD': 'lightblue', 'Intel': 'lightgreen'}))
plt.xlabel('Unit Runtime')
plt.ylabel('Machine Name')
plt.title('Unit Runtimes at 1 Core for All Machines')
plt.grid(axis='x')

# Show the plot
plt.show()


# Now, create another plot with the unit runtime based on the lowest runtime in each machine's dataset, and dividing it by 10.98 (use intermediate dataframe to calculate)
# Then, add that data back to sorted_merged_data and plot it in a horizontal bar chart (so it stays in the same sort order as the previous plot)

# build intermediate dataframe with only the lowest runtime for each machine
lowest_runtime = merged_data.groupby('Machine Index')['Runtime (min)'].min().reset_index()
lowest_runtime['Unit Runtime'] = lowest_runtime['Runtime (min)'] / 10.98
# Get the base clock from merged_data and use it to calculate the columns
lowest_runtime = lowest_runtime.merge(merged_data[['Machine Index', 'Machine Name', 'CPU Base Clock Speed (GHz)']], on='Machine Index', how='left')
lowest_runtime['CPU Clock Cycles (Effort)'] = lowest_runtime['Unit Runtime'] * lowest_runtime['CPU Base Clock Speed (GHz)'] * 60
lowest_runtime['Used (GHZ-Hr)'] = lowest_runtime['CPU Clock Cycles (Effort)'] / 3600
lowest_runtime['CPU Efficiency Coefficient'] = lowest_runtime['Runtime (min)'] / lowest_runtime['Used (GHZ-Hr)']
display(lowest_runtime)
# Add lowest runtime data to sorted_merged_data
sorted_merged_data['Lowest Runtime'] = lowest_runtime['Runtime (min)']
sorted_merged_data['Lowest Unit Runtime'] = lowest_runtime['Unit Runtime']
sorted_merged_data['CPU Clock Cycles (Effort)'] = lowest_runtime['CPU Clock Cycles (Effort)']
sorted_merged_data['Used (GHZ-Hr)'] = lowest_runtime['Used (GHZ-Hr)']
sorted_merged_data['CPU Efficiency Coefficient'] = lowest_runtime['CPU Efficiency Coefficient']
sorted_merged_data['CPU Base Clock Speed (GHz)'] = lowest_runtime['CPU Base Clock Speed (GHz)']
display(sorted_merged_data)






# Plot lowest unit runtime in bar chart identical to above
plt.figure(figsize=(10, len(sorted_merged_data) / 1.5))  # Adjusting figure size based on number of entries
plt.barh(sorted_merged_data['Machine Name'], sorted_merged_data['Lowest Unit Runtime'], color=sorted_merged_data['Manufacturer'].map({'AMD': 'lightblue', 'Intel': 'lightgreen'}))
plt.xlabel('Lowest Unit Runtime')
plt.ylabel('Machine Name')
plt.title('Unit Runtimes @ Lowest Runtime for Each Machines')
plt.grid(axis='x')

# Show the plot
plt.show()

# Check if 'CPU Base Clock Speed (GHz)' is in the dataframe
if 'CPU Base Clock Speed (GHz)' in sorted_merged_data.columns:
    # Calculate CPU Unit Effort @ 1 Core using Unit Runtime and Base Clock Speed
    sorted_merged_data['CPU Unit Effort @ 1 Core'] = sorted_merged_data['Lowest Unit Runtime'] * sorted_merged_data['CPU Base Clock Speed (GHz)'] * 60 / 3600 /0.056667
    display(sorted_merged_data)
else:
    print("'CPU Base Clock Speed (GHz)' is not in the dataframe. Please check the column name.")




# Plot CPU Unit Effort @ 1 Core in bar chart identical to above
plt.figure(figsize=(10, len(sorted_merged_data) / 1.5))  # Adjusting figure size based on number of entries
if 'CPU Unit Effort @ 1 Core' in sorted_merged_data.columns:
    plt.barh(sorted_merged_data['Machine Name'], sorted_merged_data['CPU Unit Effort @ 1 Core'], color='lightgrey')  # Neutral color scheme
    plt.xlabel('CPU Unit Effort @ 1 Core')
    plt.ylabel('Machine Name')
    plt.title('CPU Unit Effort @ 1 Core for Each Machine')
    plt.grid(axis='x')
else:
    print("'CPU Unit Effort @ 1 Core' is not in the dataframe. Please check the column name.")

# Show the plot
plt.show()



# Plot CPU Unit Effort @ Lowest Runtime for Each Machines
plt.figure(figsize=(10, len(sorted_merged_data) / 1.5))  # Adjusting figure size based on number of entries
plt.barh(sorted_merged_data['Machine Name'], sorted_merged_data['Lowest Unit Runtime'], color='lightgrey')  # Neutral color scheme
plt.xlabel('CPU Unit Effort at Lowest Unit Runtime')
plt.ylabel('Machine Name')
plt.title('CPU Unit Effort @ Lowest Runtime vs Unit Effort at 1 Core for Each Machine')
plt.grid(axis='x')

# Add CPU Effort in Unit Terms to the chart
sorted_merged_data['CPU Effort (Unit Terms)'] = sorted_merged_data['CPU Clock Cycles (Effort)'] / 193.764706
plt.barh(sorted_merged_data['Machine Name'], sorted_merged_data['CPU Effort (Unit Terms)'], color='blue', alpha=0.2)  # Less prominent


# Show the plot
plt.show()

```

</details>

### Raw Data and Dataframes
Benchmarking data and generated dataframes are provided as CSV files: 
[Zip File with Benchmarking Dataframes](https://github.com/billk-FM/HEC-Commander/blob/68230415dc59e8e6ccd8f5747e48830d9d3d5277/Blog/img/benchmarking_dataframes.zip)



#### Platforms Tested:  machine_names.csv
<details>
<summary> Platforms Tested:  machine_names.csv (Click to Expand)</summary>


| Machine Index | Machine Name                                                          | CPU Base Clock Speed (GHz) |
|---------------|-----------------------------------------------------------------------|----------------------------|
| 0             | Microsoft Azure FSV2, Xeon Platinum 8272CL                            | 2.6                        |
| 1             | Microsoft Azure VM, AMD EPYC 7V12                                     | 2.44                       |
| 2             | Microsoft Azure FSV2 Baremetal Instance, Xeon Platinum 8270C, 128 GB  | 2.8                        |
| 3             | OpenMetal Private Cloud (2 x Intel Xeon Gold 6338 CPU, 32-Core/64-Thread)| 2                          |
| 4             | Servers.com (Intel Xeon E-2288G CPU, 128 GB RAM)                      | 3.7                        |
| 5             | AWS c6i.8xlarge (Intel Ice Lake Xeon Platinum 8375C) (Linux Solver)   | 2.9                        |
| 6             | AWS c6i.24xlarge (Intel Ice Lake Xeon Platinum 8375C) (Linux Solver)  | 2.9                        |
| 7             | AWS c6i.8xlarge (Intel Ice Lake Xeon Platinum 8375C) (Windows Instance)| 2.9                       |
| 8             | AWS c5a.8xlarge (AMD EPYC 7R32) (Linux Solver)                        | 3.3                        |
| 9             | Midrange Laptop (Intel Core i7-1070H, 32GB)                           | 2.59                       |
| 10            | Midrange Desktop (Intel i9-9900) (No HT)                              | 3.1                        |
| 11            | Midrange Desktop (Intel i9-9900) - 64GB RAM, Mapped Drive             | 3.1                        |
| 12            | Midrange Desktop i9-9900 (with HT)                                    | 3.1                        |
| 13            | Fenstermaker HPC (12th Gen i9-12900K 64 GB) (Cloud Test Environment)  | 3.19                       |
| 14            | Fenstermaker HPC (12th Gen i9-12900K 64 GB) (Hardware Defaults)       | 3.4                        |
| 15            | Dell Rack Machine (AMD 16 core x 2, 3.49GHz, 64GB RAM)                | 3.49                       |
| 16            | Dell Precision 7920 Tower (Intel Xeon Gold 6246R CPU, 3.40 GHz, 192 GB Ram)| 3.4                    |
| 17            | Dell Rack Machine (Hyper V AMD, 10 vCPU, 3.49GHz, 16GB RAM, 128 GB drive)| 3.49                   |
| 18            | Microsoft Azure FX12mds (Intel Xeon Gold 6246R CPU, 252 GB RAM)       | 3.4                        |
| 19            | Microsoft Azure F72s (Intel Xeon Platinum 8370C CPU 144GB RAM)        | 2.8                        |
| 20            | Intel Xeon Gold 6248R (32 GB RAM) (Cloud Test Environment)            | 3                          |
| 21            | Fenstermaker HPC (12th Gen i9-12900K 64 GB) (Optimized, No HT, No Eff Cores)| 3.4                 |


</details>


#### Raw Runtime Results:  performance_data.csv

<details>
<summary>Raw Runtime Results:  performance_data.csv (Click to Expand)</summary>

| Machine Index | Cores | Runtime (min) |
|---------------|-------|---------------|
| 0             | 1     | 98.78333333   |
| 0             | 2     | 54.43333333   |
| 0             | 3     | 50.1          |
| 0             | 4     | 35.23333333   |
| 0             | 5     | 32.96666667   |
| 0             | 6     | 30.68333333   |
| 0             | 7     | 29.33333333   |
| 0             | 8     | 28.53333333   |
| 0             | 9     | 27.55         |
| 0             | 10    | 27.03333333   |
| 0             | 11    | 27.03333333   |
| 0             | 12    | 25.76666667   |
| 0             | 13    | 25.38333333   |
| 0             | 14    | 26.76666667   |
| 0             | 15    | 28.03333333   |
| 0             | 16    | 28.53333333   |
| 1             | 1     | 83.00916667   |
| 1             | 2     | 48.3          |
| 1             | 3     | 41.68333333   |
| 1             | 4     | 33.93333333   |
| 1             | 5     | 31.56666667   |
| 1             | 6     | 29.71666667   |
| 1             | 7     | 28.7          |
| 1             | 8     | 27.88333333   |
| 1             | 9     | 27.46666667   |
| 1             | 10    | 27.1          |
| 1             | 11    | 26.7          |
| 1             | 12    | 26.6          |
| 1             | 13    | 26.26666667   |
| 1             | 14    | 26.15         |
| 1             | 15    | 26.21666667   |
| 1             | 16    | 29.73333333   |
| 2             | 1     | 74.16666667   |
| 2             | 2     | 37.61666667   |
| 2             | 3     | 32.38333333   |
| 2             | 4     | 25.41666667   |
| 2             | 5     | 23.71666667   |
| 2             | 6     | 22.08333333   |
| 2             | 7     | 21.76666667   |
| 2             | 8     | 21.23333333   |
| 2             | 9     | 20.63333333   |
| 2             | 10    | 20             |
| 2             | 11    | 20.03333333   |
| 2             | 12    | 19.8           |
| 2             | 13    | 19.83333333   |
| 2             | 14    | 19.76666667   |
| 2             | 15    | 19.55          |
| 2             | 16    | 19.53333333   |
| 3             | 1     | 74.25          |
| 3             | 2     | 40.01666667   |
| 3             | 3     | 36.11666667   |
| 3             | 4     | 31.88333333   |
| 3             | 5     | 32.71666667   |
| 3             | 6     | 32.03333333   |
| 3             | 7     | 32.7           |
| 3             | 8     | 31.6           |
| 3             | 9     | 32.53333333   |
| 3             | 10    | 32.88333333   |
| 3             | 11    | 32.95          |
| 3             | 12    | 33.1           |
| 3             | 13    | 33.01666667   |
| 3             | 14    | 32.83333333   |
| 3             | 15    | 33.13333333   |
| 3             | 16    | 31.76666667   |
| 4             | 1     | 67.73333333   |
| 4             | 2     | 36.71666667   |
| 4             | 3     | 31.43333333   |
| 4             | 4     | 25.03333333   |
| 4             | 5     | 23.35          |
| 4             | 6     | 21.96666667   |
| 4             | 7     | 21.53333333   |
| 4             | 8     | 21.21666667   |
| 4             | 9     | 21.21666667   |
| 4             | 10    | 21.08333333   |
| 4             | 11    | 21.2           |
| 4             | 12    | 21.2           |
| 4             | 13    | 21.18333333   |
| 4             | 14    | 20.78333333   |
| 4             | 15    | 20.76666667   |
| 4             | 16    | 20.93333333   |
| 5             | 1     | 52.33          |
| 5             | 2     | 32.03          |
| 5             | 3     | 27.4           |
| 5             | 4     | 21.88          |
| 5             | 8     | 17.13          |
| 5             | 12    | 15.78          |
| 5             | 16    | 14.88          |
| 6             | 16    | 17.22          |
| 6             | 24    | 16.67          |
| 6             | 48    | 16.12          |
| 7             | 16    | 17.23          |
| 8             | 16    | 20.95          |
| 9             | 1     | 62.95          |
| 9             | 2     | 34.83          |
| 9             | 3     | 29.97          |
| 9             | 4     | 25.02          |
| 9             | 5     | 24.05          |
| 9             | 6     | 24.25          |
| 10            | 1     | 59.48          |
| 10            | 2     | 30.88          |
| 10            | 3     | 23.57          |
| 10            | 5     | 19.65          |
| 10            | 6     | 20.15          |
| 10            | 7     | 19.77          |
| 10            | 8     | 20.55          |
| 11            | 1     | 54.65          |
| 11            | 2     | 29.98          |
| 11            | 3     | 26.05          |
| 11            | 4     | 21.58          |
| 11            | 5     | 20.57          |
| 11            | 6     | 19.68          |
| 11            | 7     | 20.6           |
| 11            | 8     | 19.78          |
| 12            | 1     | 54.63          |
| 12            | 2     | 30              |
| 12            | 3     | 26.2           |
| 12            | 4     | 21.52          |
| 12            | 5     | 20.5           |
| 12            | 6     | 20.73          |
| 12            | 7     | 19.55          |
| 12            | 8     | 19.87          |
| 13            | 8     | 11.55          |
| 13            | 16    | 14.12          |
| 14            | 1     | 35.65          |
| 14            | 2     | 19.08          |
| 14            | 3     | 17.45          |
| 14            | 4     | 14.32          |
| 14            | 5     | 13.65          |
| 14            | 6     | 12.42          |
| 14            | 7     | 12.1           |
| 14            | 8     | 11.98          |
| 14            | 10    | 13.35          |
| 14            | 12    | 14.33          |
| 14            | 14    | 14.73          |
| 14            | 16    | 15              |
| 14            | 18    | 14.97          |
| 14            | 20    | 15.03          |
| 14            | 24    | 15.07          |
| 15            | 1     | 113.52         |
| 15            | 2     | 72.22          |
| 15            | 3     | 61.5           |
| 15            | 4     | 44.97          |
| 15            | 5     | 44.03          |
| 15            | 6     | 46.32          |
| 15            | 7     | 45.8           |
| 15            | 8     | 40.17          |
| 15            | 9     | 39.68          |
| 15            | 10    | 38.07          |
| 15            | 11    | 42.52          |
| 15            | 12    | 40.28          |
| 15            | 13    | 36.62          |
| 15            | 14    | 40.15          |
| 15            | 15    | 39.25          |
| 16            | 1     | 77.4           |
| 16            | 2     | 40.12          |
| 16            | 3     | 34.03          |
| 16            | 4     | 30.52          |
| 16            | 5     | 26.28          |
| 16            | 6     | 30.9           |
| 16            | 7     | 22.8           |
| 16            | 8     | 22.2           |
| 16            | 9     | 21.1           |
| 16            | 10    | 26.07          |
| 16            | 11    | 25.52          |
| 16            | 12    | 20.18          |
| 16            | 13    | 24.52          |
| 16            | 14    | 23.68          |
| 16            | 15    | 24.35          |
| 16            | 16    | 23.3           |
| 17            | 8     | 31.15          |
| 18            | 1     | 83.18          |
| 18            | 2     | 44.37          |
| 18            | 3     | 37.33          |
| 18            | 4     | 30.55          |
| 18            | 5     | 28.73          |
| 18            | 6     | 27.58          |
| 18            | 7     | 27.47          |
| 18            | 8     | 27.42          |
| 18            | 9     | 27.32          |
| 18            | 10    | 27.55          |
| 18            | 11    | 26.95          |
| 18            | 12    | 28.02          |
| 18            | 13    | 27.92          |
| 18            | 14    | 28.15          |
| 18            | 15    | 27.87          |
| 18            | 16    | 27.77          |
| 19            | 1     | 74.27          |
| 19            | 2     | 37.7           |
| 19            | 3     | 32.32          |
| 19            | 4     | 26.03          |
| 19            | 5     | 23.33          |
| 19            | 6     | 22.07          |
| 19            | 7     | 22.53          |
| 19            | 8     | 21.78          |
| 19            | 9     | 21.22          |
| 19            | 10    | 20.62          |
| 19            | 11    | 20.85          |
| 19            | 12    | 20.58          |
| 19            | 13    | 20.6           |
| 19            | 14    | 20.45          |
| 19            | 15    | 20.3           |
| 19            | 16    | 20.57          |
| 20            | 1     | 83.97          |
| 20            | 2     | 44.4           |
| 20            | 3     | 37.72          |
| 20            | 4     | 30.32          |
| 20            | 5     | 27.62          |
| 20            | 6     | 27.83          |
| 20            | 7     | 26.33          |
| 20            | 8     | 28.47          |
| 20            | 9     | 28.67          |
| 20            | 10    | 29.1           |
| 20            | 11    | 28.6           |
| 20            | 12    | 28.98          |
| 20            | 13    | 28.42          |
| 20            | 14    | 29             |
| 20            | 15    | 28.55          |
| 20            | 16    | 28.45          |
| 21            | 1     | 35.82          |
| 21            | 2     | 19.55          |
| 21            | 3     | 16.92          |
| 21            | 4     | 13.48          |
| 21            | 5     | 12.32          |
| 21            | 6     | 11.55          |
| 21            | 7     | 11.12          |
| 21            | 8     | 10.98          |


</details>


#### Machine Name and Runtime (Merged):  merged_data.csv
This dataframe is the merged dataframe with machine names and raw performance results (not included here as it is duplicated above)


#### Unit_Runtimes:  UnitRuntimes.csv


<details>
<summary>Unit Runtimes at 1 Core (Click to Expand)</summary>

| #   | Machine Name                                                           | Unit Runtime            | Manufacturer | Machine Index |
|-----|------------------------------------------------------------------------|-------------------------|--------------|---------------|
| 218 | Fenstermaker HPC (12th Gen i9-12900K 64 GB) (Optimized, No HT, No Eff Cores) | 1.0                   | Intel        |               |
| 123 | Fenstermaker HPC (12th Gen i9-12900K 64 GB) (Hardware Defaults)        | 1.37                    | Intel        |               |
| 80  | AWS c6i.8xlarge (Intel Ice Lake Xeon Platinum 8375C) (Linux Solver)   | 1.4609156895589055      | Intel        |               |
| 113 | Midrange Desktop i9-9900 (with HT)                                     | 1.5251256281407035      | Intel        |               |
| 105 | Midrange Desktop (Intel i9-9900) - 64GB RAM, Mapped Drive              | 1.5256839754327192      | Intel        |               |
| 98  | Midrange Desktop (Intel i9-9900) (No HT)                               | 1.6605248464544946      | Intel        |               |
| 92  | Midrange Laptop (Intel Core i7-1070H, 32GB)                            | 1.7573981016192073      | Intel        |               |
| 64  | Servers.com (Intel Xeon E-2288G CPU, 128 GB RAM)                       | 1.8909361621998881      | Intel        |               |
| 8   | AWS c5a.8xlarge (AMD EPYC 7R32) (Linux Solver)                         | 1.9                     | AMD          | 8.0           |
| 32  | Microsoft Azure FSV2 Baremetal Instance, Xeon Platinum 8270C, 128 GB   | 2.070537874651033       | Intel        |               |
| 48  | OpenMetal Private Cloud (2 x Intel Xeon Gold 6338 CPU, 32-Core/64-Thread) | 2.0728643216080402    | Intel        |               |
| 186 | Microsoft Azure F72s (Intel Xeon Platinum 8370C CPU 144GB RAM)         | 2.0734226689000557      | Intel        |               |
| 153 | Dell Precision 7920 Tower (Intel Xeon Gold 6246R CPU, 3.40 GHz, 192 GB Ram) | 2.1608040201005028  | Intel        |               |
| 16  | Microsoft Azure VM, AMD EPYC 7V12                                      | 2.317397171133445       | AMD          |               |
| 170 | Microsoft Azure FX12mds (Intel Xeon Gold 6246R CPU, 252 GB RAM)        | 2.322166387493021       | Intel        |               |
| 202 | Intel Xeon Gold 6248R (32 GB RAM) (Cloud Test Environment)             | 2.3442211055276383      | Intel        |               |
| 0   | Microsoft Azure FSV2, Xeon Platinum 8272CL                             | 2.7577703330541596      | Intel        |               |
| 17  | Dell Rack Machine (Hyper V AMD, 10 vCPU, 3.49GHz, 16GB RAM, 128 GB drive) | 2.83                  | AMD          | 17.0          |
| 138 | Dell Rack Machine (AMD 16 core x 2, 3.49GHz, 64GB RAM)                 | 3.169179229480737       | AMD          |               |


</details>






##





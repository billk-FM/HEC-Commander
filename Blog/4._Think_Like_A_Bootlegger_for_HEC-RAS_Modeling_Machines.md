# Thinking like a Bootlegger: Why Your HEC-RAS Modeling Machine Should be a Hot Rod, Not a Semi-Truck

<p align="center">
  <img src="img/tlab_logo.png" width="500">
</p>

HEC-RAS's finite volume solver involves tightly coupled computational fluid dynamics (CFD) calculations. These calculations are highly interdependent – data from each simulated cell needs to communicate with its neighbors at every time step for the simulation to progress. This inherent characteristic makes scaling performance across cores difficult, and even more so for the x86 processors that run our Windows workstations.

The world of high-performance computing can be a maze of specifications and marketing promises. For those of us working with HEC-RAS, it's easy to fall into the trap of thinking that sheer core count equals superior performance. However, when it comes to tightly coupled fluid dynamics modeling, I like to use the analogy of thinking like a bootlegger versus semi-trucker to offer more accurate framing.  

## Understanding the Basics of HEC-RAS Compute Performance

Let's dissect the key factors that dictate HEC-RAS performance and why a purpose-built desktop can often smoke a lumbering server:

- **The Clock Speed King:** Individual core clock speeds matter immensely in HEC-RAS. These simulations thrive on snappy, high-frequency processors that can power through computations within each time step. Fewer, but faster, cores will usually deliver a smoother and quicker modeling experience. Especially if you spend most of your time in single-threaded, CPU and storage-bound programs.

- **Memory Bandwidth is Key:** Matrix multiplications and similar calculations are the backbone of fluid dynamics simulations. These rely on lightning-fast data transfers between the processor and memory to effectively parallelize across cores. Mass-core server systems are optimized for highly parallelizable and non-interdependent workflows, and can introduce bottlenecks compared to a well-designed desktop machine where memory and CPU are tightly coupled.

- **Don't be Fooled by Hyperthreading:** Modern processors often feature virtual cores (hyperthreading). While beneficial for certain tasks, these "efficiency" cores typically operate at significantly reduced speeds. When your HEC-RAS model gets randomly assigned to them, performance nosedives. It's paramount to focus on the real, non-hyperthreaded core count and performance. Are you running HEC-RAS but wondering why your CPU usage caps at around 50%? It's because the underlying libraries don’t bother with using them, either. Real world testing consistently shows that disabling hyperthreading is better for HEC-RAS computations. Not convinced? Benchmark it yourself! Make sure to compare your core counts accurately if you do.

- **Disable “Efficiency” Cores:** If you have a newer Intel machine with “efficiency” cores, just disable them. They don’t have the SIMD instruction support you need for maximum performance in HEC-RAS calculations, and are 25% slower clock speed. Under no reasonable scenarios does it provide a benefit, it can only slow you down. Benchmark it yourself if you are imagining a scenario where it might be beneficial.

- **You Are Probably Using Too Many Cores per Run:** Most hardware configurations are unable to effectively scale across many x86-type cores for matrix multiplication (that’s why these operations have moved to GPU, and HEC-RAS has this transition on its roadmap). For most hardware, 2 non-hyperthreaded cores provide the best efficiency and 6-8 cores is optimal for maximum performance for a single run (less if the model size is small and can’t be effectively split between cores). If you aren’t convinced, benchmark it yourself! Or check out the previous blogs here on the repo.  Most CPU's are arranged in sets of 4-8 on the chip itself.

- **Consider Disabling Some Cores in the BIOS:** By stress testing your processor, you can find what level of utilization begins to trigger thermal throttling. Consider disabling any cores beyond this measure. While you may have some marginal increase in throughput past this point, your run turnaround time will suffer. For the most consistent performance on a water-cooled system, around 75% utilization is usually optimal. If you can, disable full core groups near the center of the chip to optimize the thermal layout! If you have a massively parallel machine with 32+ cores, keep your thermal monitoring software open to understand how many parallel runs you can start without hurting your turnaround times. Consider reducing the number of cores per run to maintain the most efficient configuration without significant thermal throttling.

## The Bootlegger's Hot-Rod Approach to Maximizing HEC-RAS Performance

When you hot rod your car, you want to take out the back seats, put on a turbo with an innercooler, and arrange your payload evenly to maximize traction and handling.  No nitrous - this isn't a drag strip car, it has to be built for top speed for long runs.  At least, that's the analogies I'm using to refer to picking the right platform, watercooling, and disabling features and potentially cores for consistent, sustained overclocking performance.  Here's the recipe for success:

- **Purpose-Built Machines:** Select a desktop processor renowned for its strong single-core turbo frequencies. Don't be swayed by massive core counts, as those are often designed for entirely different workloads.  An economy car will beat a semi truck when both are empty, and if you look at core scaling you will realize you aren't getting much marginal benefit from running lots of cores in most cases.  It's very common to see laptops outperform mass-core machines on a single run, especially if they are set to "All Cores".   In our analogy, thats like saying the case of booze is small enough to fit in the trunk of an economy car.  Sure, you can use all cores, but its like loading 100 cases into a semi trailer, but only delivering 1.25 at the speakeasy.  And your competition will get there days before you!

- **Thermal Overhead Matter:** Effective cooling is essential. Pushing a processor to its limits for hours, as HEC-RAS models often demand, requires a top-notch water-cooling solution to maintain consistent, high-performance operation. The goal should be to have the same turnaround time regardless of utilization, which may require leaving some cores unused. Adding 30% more parallel runs and incurring a 50% performance penalty from thermal throttling is not a winning move!  Trying to eke out marginal returns at the edge of the curve usually comes with some unanticipated nonlinearity that prevents effective performance capture.  Remember, each thread has to completely finish before the model can compare and move to the next timestep, so you will always be waiting on the slowest core/thread.

- **A Fleet, Not a Monolith:** Consider a network of optimized desktop machines for HEC-RAS work. Using tools like RAS Commander, you can remotely access and leverage this computational power seamlessly. This approach offers remarkable scalability, cost-efficiency, and beats the hassle of managing a single, complex multi-user server system that users need to manually load-balance (not to mention licensing costs).  All that for a machine that turns around runs slower than your laptop?  Why not have a screaming modeling machine for each modeler that completes runs in half the time of their laptop, but can only process 4 at a time at 2 cores?  Thats the equivalent of a 16 core machine's throughput, but any single run will finish in half the time.  Also, the entire workstation is around the same price as a mass-core CPU by itself.  How much of your total project lifecycle is constrained by running large parallel sets of runs?  If you are reading this and aren't doing JPMOS scenarios, its probably not as much as you think.  

- **Dual Use Machines:** The highest performing modeling machines are also your fastest workstations. Instead of trying to utilize other platforms such as Linux for mass compute, simply shift the usage patterns of your workstations around to accommodate workstation use in the model setup phase, and compute use in later stages.  This is how RAS-Commander was concepted - as a tool to utilize additional machines for parallel compute after model development efforts slowed down and resources were underutilized.  

- **Look at the Chip Layout:** The speed of light hasn’t changed. Processors aren’t magic. Look at the physical chip layout of your machine, and you might find clues about its performance profile. Caching hierarchies can induce heavy penalties for crossing intra-chip boundaries, but even if that means nothing to you, its not hard to look at a chip layout and see the size of the groups of cores.  Using more than one group of cores on the chip effectively is unlikely, since they are further apart. Tightly coupled calculations need to have threads located close together on the chip, and ideally should have shared L2 or L3 cache (depending on the processor architecture).

- **Understand the Definitive Limitations:** Long pipeline x86 architecture on top of a Microsoft Windows kernel just isn’t going to scale CFD calculations to very many cores. The same architecture on a Linux kernel can do marginally better (~15% or so on average) but can’t change the chip’s architectural limitations. It’s not that we don’t have enough cores, I can buy 128 core beast tomorrow and run Linux on a bare metal instance and it still won’t scale the way we all wish it would. The GPU solver on the HEC-RAS roadmap can’t come soon enough!  

## Tangible Benefits of the Hot Rod Approach

- **The Gift of Time:** Quicker runtimes translate into a revolutionized workflow. Time saved waiting on results means more time for thoughtful analysis, scenario exploration, and model refinement. More consistent runtimes mean you aren’t taken by surprised by your model taking 20-50% longer to run due to thermal throttling, and your workflows are more predictable.

- **Financial Flexibility:** Properly specified desktops can massively undercut a hefty server’s price tag. This translates into budget savings that you can reinvest in software, training, or other resources to advance your modeling capabilities. Resources can be added incrementally, as long as they maintain high-speed network interconnects needed for parallel execution.

- **No Cloud Incentive:** What bootlegger in their right mind would partner with a company that makes semi trucks? Can you control your thermal profile to ensure the overclocking margin? Do you even know if your VCPU’s are actually hyperthreaded? I didn’t think so.  If your consultants say they can assure all those things, have them benchmark at their own expense.  Cloud providers simply don’t sell hot rods, they at best will sell you a sprinter van.  But if you show up at the dealership asking for a high-margin profit machine, you can rest assured you wont end up with an economic purchase.  If there is no scat pack on the lot, look somewhere else.  Always test run on your own track where you can control the conditions and the fine tuning before finalizing a purchase.  Walk away from any place that refuses a thorough test drive.  

## The Bottom Line: It's About the User Experience

The goal with any computational tool should be to empower the user, not to wrestle with the tool itself. By rethinking our approach to optimizing HEC-RAS performance, we unlock a world of faster iteration, greater efficiency, consistency, and a more productive modeling workflow.

## Be Your Own Expert

We often pay for others to be the IT experts.  In most cases this is totally adequate.  But when you are facing challenges from relatively ancient and rarely upgraded software that still has a Windows 32-bit style interface, you may have a tough time finding consensus.  Asking experts who deal exclusively with more modern software packages, managed infrastructure and cloud solutions, you might get brushed off when you assert things like: "hey disable my hyperthreading, its faster", "this $15k machine is slower than my laptop", "disable some of my cores", etc.  Do your own benchmarking, be your own expert.  HEC-RAS is not modern software nor is it built for you.  Nor is it likely to change for you.  The CPU architectural limitations, just like the speed of light, also aren't changing.  You aren't going to be able to point at some sassy blog on the internet to convince them, either.  Benchmark it yourself, its your time at stake.  Its your projects that will succeed and be profitable, or your nights and weekends saved by not having to babysit runs or assert to your client that runtimes are prohibitive.  The best way to ensure your success is to understand the mechanics behind it.  That will give you the tools for success regardless of whether your needs are within someone else's uncanny valley.  

## Conclusion

Until we get GPU accelleration in HEC-RAS, think like a bootlegger when hotrodding your HEC-RAS machine.  Only a precious few entities are running at a scale.

These optimizations will help real-time forecasting models, too.  They depend on turnaround time but I often see people mistakenly pushing those to mass core servers.  This may make sense for automation and uptime but I know from my benchmarking that there is probably a 30-40% performance gap from a optimally specified system.  I hope this blog helps someone in charge of those systems with some additional insights.

<br></br>

Thank you for reading this installment of my blog series on/by AI and Automation in Water Resources Engineering! For more, please follow my LinkedIn Page or stay tuned in the HEC-Commander Github page If you want to talk more about Water Resources or Management Consulting Services for your firm, reach out to me at billk@fenstermaker.com

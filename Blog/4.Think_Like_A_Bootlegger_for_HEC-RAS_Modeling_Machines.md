# Think Like a Bootlegger: Why Your HEC-RAS Modeling Machine Shouldn't Be a Semi-Truck

HEC-RAS, at its core, involves tightly coupled computational fluid dynamics (CFD) calculations. These calculations are highly interdependent – data from each simulated cell needs to communicate with its neighbors at every time step for the simulation to progress. This inherent characteristic makes scaling performance across cores difficult, and even more so for the x86 processors that run our Windows workstations.

The world of high-performance computing can be a maze of specifications and marketing promises. For those of us working with HEC-RAS, it's easy to fall into the trap of thinking that sheer core count equals superior performance. However, when it comes to tightly coupled fluid dynamics modeling, I like to use the analogy of thinking like a bootleggers versus semi-trucker to offer more accurate framing.

## Understanding the Basics of HEC-RAS Compute Performance

Let's dissect the key factors that dictate HEC-RAS performance and why a purpose-built desktop can often smoke a lumbering server:

- **The Clock Speed King:** Individual core clock speeds matter immensely in HEC-RAS. These simulations thrive on snappy, high-frequency processors that can power through computations within each time step. Fewer, but faster, cores will usually deliver a smoother and quicker modeling experience. Especially if you spend most of your time in single-threaded, CPU and storage-bound programs.

- **Memory Bandwidth is Key:** Matrix multiplications and similar calculations are the backbone of fluid dynamics simulations. These rely on lightning-fast data transfers between the processor and memory to effectively parallelize across cores. Multi-socket server systems, with their distributed memory architecture, can introduce bottlenecks compared to a well-designed desktop machine where memory and CPU are tightly coupled.

- **Don't be Fooled by Hyperthreading:** Modern processors often feature virtual cores (hyperthreading). While beneficial for certain tasks, these "efficiency" cores typically operate at significantly reduced speeds. When your HEC-RAS model gets randomly assigned to them, performance nosedives. It's paramount to focus on the real, non-hyperthreaded core count and performance. Are you running HEC-RAS but wondering why your CPU usage caps at around 50%? It's because the underlying libraries don’t bother with using them, either. Real world testing consistently shows that disabling hyperthreading is better for HEC-RAS computations. Not convinced? Benchmark it yourself! Make sure to compare your core counts accurately if you do.

- **Disable “Efficiency” Cores:** If you have a newer Intel machine with “efficiency” cores, just disable them. They don’t have the SIMD instruction support you need for maximum performance in HEC-RAS calculations, and are 25% slower clock speed. Under no reasonable scenarios does it provide a benefit, it can only slow you down. Benchmark it yourself if you are imagining a scenario where it might be beneficial.

- **You Are Probably Using Too Many Cores per Run:** Most hardware configurations are unable to effectively scale across many x86-type cores for matrix multiplication (that’s why these operations have moved to GPU, and HEC-RAS has this transition on its roadmap). For most hardware, 2 non-hyperthreaded cores provide the best efficiency and 6-8 cores is optimal for maximum performance for a single run (less if the model size is small and can’t be effectively split between cores). If you aren’t convinced, benchmark it yourself! Or check out the previous blogs here on the repo.

- **Consider Disabling Some Cores in the BIOS:** By stress testing your processor, you can find what level of utilization begins to trigger thermal throttling. Consider disabling any cores beyond this measure. While you may have some marginal increase in throughput past this point, your run turnaround time will suffer. For the most consistent performance on a water-cooled system, around 75% utilization is usually optimal. If you can, disable full core groups near the center of the chip to optimize the thermal layout! If you have a massively parallel machine with 32+ cores, keep your thermal monitoring software open to understand how many parallel runs you can start without hurting your turnaround times. Consider reducing the number of cores per run to maintain the most efficient configuration without significant thermal throttling.

## The Bootlegger's Toolkit for HEC-RAS Performance

Think speed, agility, and efficiency. Here's the recipe for success:

- **Purpose-Built Machines:** Select a desktop processor renowned for its strong single-core turbo frequencies. Don't be swayed by massive core counts, as those are often designed for entirely different workloads.

- **Thermals Matter:** Effective cooling is essential. Pushing a processor to its limits for hours, as HEC-RAS models often demand, requires a top-notch water-cooling solution to maintain consistent, high-performance operation. The goal should be to have the same turnaround time regardless of utilization, which may require leaving some cores unused. Adding 30% more parallel runs and incurring a 50% performance penalty from thermal throttling is not a winning move!

- **A Fleet, Not a Monolith:** Consider a network of optimized desktop machines for HEC-RAS work. Using tools like RAS Commander, you can remotely access and leverage this computational power seamlessly. This approach offers remarkable scalability, cost-efficiency, and beats the hassle of managing a single, complex server system.

- **Dual Use Machines:** The highest performing modeling machines are also your fastest workstations. Instead of trying to utilize other platforms such as Linux for mass compute, simply shift the usage patterns of your workstations around to accommodate workstation use in the model setup phase, and compute use in later stages.

- **Look at the Chip Layout:** The speed of light hasn’t changed. Processors aren’t magic. Look at the physical chip layout of your machine, and you might find clues about its performance profile. Caching hierarchies can induce heavy penalties for crossing intra-chip boundaries. Tightly coupled calculations need to have threads located close together on the chip, and ideally should have shared L2 or L3 cache (depending on the processor architecture).

- **Understand the Definitive Limitations:** Long pipeline x86 architecture on top of a Microsoft Windows kernel just isn’t going to scale CFD calculations to very many cores. The same architecture on a Linux kernel can do marginally better (~15% or so on average) but can’t change the chip’s architectural limitations. It’s not that we don’t have enough cores, I can buy 128 core beast tomorrow and run Linux on a bare metal instance and it still won’t scale the way we all wish it would. The GPU solver on the HEC-RAS roadmap can’t come soon enough.

## Tangible Benefits of the Bootlegger Approach

- **The Gift of Time:** Quicker runtimes translate into a revolutionized workflow. Time saved waiting on results means more time for thoughtful analysis, scenario exploration, and model refinement. More consistent runtimes mean you aren’t taken by surprised by your model taking 20-50% longer to run due to thermal throttling, and your workflows are more predictable.

- **Financial Flexibility:** Properly specified desktops can massively undercut a hefty server’s price tag. This translates into budget savings that you can reinvest in software, training, or other resources to advance your modeling capabilities. Resources can be added incrementally, as long as they maintain high-speed network interconnects needed for parallel execution.

- **No Cloud Incentive:** What bootlegger in their right mind would partner with a company that makes semi trucks? Can you control your thermal profile to ensure the overclocking margin? Do you even know if your VCPU’s are actually hyperthreaded? I didn’t think so. Cloud providers don’t sell hot rods, they at best will sell you a sprinter van.

## The Bottom Line: It's About the User Experience

The goal with any computational tool should be to empower the user, not to wrestle with the tool itself. By rethinking our approach to optimizing HEC-RAS performance, we unlock a world of faster iteration, greater efficiency, consistency, and a more productive modeling workflow.

<br></br>

Thank you for reading my first installment of my blog series on/by AI and Automation in Water Resources Engineering! For more, please follow my LinkedIn Page or stay tuned in the HEC-Commander Github page If you want to talk more about Water Resources or Management Consulting Services for your firm, reach out to me at billk@fenstermaker.com
